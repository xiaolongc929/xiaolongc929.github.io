<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="xiaolongc">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="xiaolongc">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="xiaolongc">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>xiaolongc</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">xiaolongc</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2099/01/01/Contents/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenxiaolong">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xiaolongc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2099/01/01/Contents/" itemprop="url">博客目录</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2099-01-01T00:00:00+08:00">
                2099-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/目录/" itemprop="url" rel="index">
                    <span itemprop="name">目录</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="机器学习基石-amp-技巧"><a href="#机器学习基石-amp-技巧" class="headerlink" title="机器学习基石&amp;技巧"></a>机器学习基石&amp;技巧</h1><ul>
<li>1 <a href="https://xiaolongc929.github.io/2019/03/16/The-Learning-Problem/" target="_blank" rel="noopener">The-Learning-Problem</a></li>
<li>2 <a href="https://xiaolongc929.github.io/2019/03/17/Learning-to-answer-yes-no/" target="_blank" rel="noopener">Learning-to-answer-yes-no</a></li>
<li>3 <a href="https://xiaolongc929.github.io/2019/03/31/Types-of-learning/" target="_blank" rel="noopener">Types-of-learning</a></li>
<li>4 <a href="https://xiaolongc929.github.io/2019/04/05/Feasibility-of-learning/" target="_blank" rel="noopener">Feasibility-of-learning</a></li>
<li>5 <a href="https://xiaolongc929.github.io/2019/05/26/Training-versus-Testing/" target="_blank" rel="noopener">Training-versus-Testing</a></li>
<li>6 <a href="https://xiaolongc929.github.io/2019/06/23/Theory-of-Generalization/" target="_blank" rel="noopener">Theory-of-Generalization</a></li>
</ul>
<h1 id="机器学习原理"><a href="#机器学习原理" class="headerlink" title="机器学习原理"></a>机器学习原理</h1><ul>
<li>1 <a href="https://xiaolongc929.github.io/2019/07/27/Decision-tree/" target="_blank" rel="noopener">Decision-tree</a></li>
<li>2 <a href="https://xiaolongc929.github.io/2019/08/03/AdaBoost/" target="_blank" rel="noopener">AdaBoost</a></li>
<li>3 <a href="https://xiaolongc929.github.io/2019/08/07/GBDT/" target="_blank" rel="noopener">GBDT</a></li>
<li>4 <a href="https://xiaolongc929.github.io/2019/09/01/xgboost/" target="_blank" rel="noopener">xgboost</a></li>
<li>5 <a href="https://xiaolongc929.github.io/2019/09/01/fbprophet/" target="_blank" rel="noopener">fbprophet</a></li>
</ul>
<h1 id="时间序列"><a href="#时间序列" class="headerlink" title="时间序列"></a>时间序列</h1><h1 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h1><ul>
<li><a href="https://xiaolongc929.github.io/2019/03/12/hadoop-spark-install/" target="_blank" rel="noopener">macoc 下 hadoop spark 安装和配置</a></li>
<li><a href="https://xiaolongc929.github.io/2019/07/06/Programming-Hive/" target="_blank" rel="noopener">Hive 编程指南</a></li>
</ul>
<h1 id="运筹规划"><a href="#运筹规划" class="headerlink" title="运筹规划"></a>运筹规划</h1><h1 id="云计算"><a href="#云计算" class="headerlink" title="云计算"></a>云计算</h1><h1 id="Java-语言"><a href="#Java-语言" class="headerlink" title="Java 语言"></a>Java 语言</h1><h1 id="Python-语言"><a href="#Python-语言" class="headerlink" title="Python 语言"></a>Python 语言</h1><h1 id="C-语言"><a href="#C-语言" class="headerlink" title="C++ 语言"></a>C++ 语言</h1><h1 id="经典算法"><a href="#经典算法" class="headerlink" title="经典算法"></a>经典算法</h1><h1 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h1><ul>
<li>1 <a href="https://xiaolongc929.github.io/2019/02/17/Hexo-HelloWorld/" target="_blank" rel="noopener">Hexo-HelloWorld</a></li>
<li>2 <a href="https://xiaolongc929.github.io/2019/03/10/hexo-action/" target="_blank" rel="noopener">hexo-实战</a></li>
<li>3 <a href="https://xiaolongc929.github.io/2019/03/12/hadoop-spark-install/" target="_blank" rel="noopener">macoc 下 hadoop spark 安装和配置</a></li>
</ul>
<h1 id="工具使用"><a href="#工具使用" class="headerlink" title="工具使用"></a>工具使用</h1><ul>
<li>1 <a href="https://xiaolongc929.github.io/2019/03/08/maven-action/" target="_blank" rel="noopener">maven实战</a></li>
</ul>
<h1 id="阅读感想"><a href="#阅读感想" class="headerlink" title="阅读感想"></a>阅读感想</h1><h1 id="个人随笔"><a href="#个人随笔" class="headerlink" title="个人随笔"></a>个人随笔</h1><ul>
<li>1 <a href="https://xiaolongc929.github.io/2019/03/10/Join-the-Internet-industry/" target="_blank" rel="noopener">加入互联网行业</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/21/convex-optimization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenxiaolong">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xiaolongc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/21/convex-optimization/" itemprop="url">6. 凸优化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-21T10:50:43+08:00">
                2019-12-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">machine learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p><strong>凸优化之所以如此重要，是因为凸优化的重要特性：凸优化的任意局部最优解也是全局最优解</strong></p>
<h2 id="数学优化"><a href="#数学优化" class="headerlink" title="数学优化"></a>数学优化</h2><p>数学优化问题定义(1.1):</p>
<p>$$minimize\ f_{0}(x)$$<br>$$subject\ to\ f_{i}(x)&lt;=b_{i}, i=1,…,m$$</p>
<ul>
<li>其中，向量$x=(x_{1},x_{2},…,x_{n})$称为问题的优化变量</li>
<li>函数$f_{0}:R^{n}\rightarrow R$称为目标函数</li>
<li>函数$f_{i}:R^{n}\rightarrow R,\ i=1,…,m$称为(不等式)约束函数</li>
<li>常数$b_{1},…,b_{m}$称为约束上限或者约束边界</li>
</ul>
<p>对于任意满足约束$f_{1}(z)&lt;=b1,…,f_{m}(z)&lt;=b_{m}$的向量$z$，有$f_{0}(z)&gt;=f_{0}(x^{<em>})$,那么称$x^{</em>}$为上述问题的最优解.</p>
<p>线性规划(1.2)：</p>
<p>若优化问题(1.1)中的目标函数和约束函数$f_{0},…,f_{m}$都是线性函数，即对任意的$x,y\in R^{n}$和$\alpha,\beta\in R$有:</p>
<p>$$f_{i}(\alpha x+\beta y)=\alpha f_{i}(x)+\beta f_{i}(y).$$</p>
<p>则此优化问题称为线性规划，若优化问题不是线性的，则称之为非线性优化。</p>
<p><strong>最小二乘问题</strong></p>
<p>最小二乘问题是其中的一个优化特例，它没有约束条件(即$m=0$)，目标函数是若干项的平方和，每一项具有形式$a_{i}^{T}x-b_{i}$，具体形式如下(1.4):</p>
<p>$$minimize\ f_{0}(x)=||Ax-b||<em>{2}^{2}=\sum</em>{i=1}^{k}(a_{i}^{T}x-b_{i})^{2}.$$</p>
<ul>
<li>其中，$A\in R^{k*n}(k&gt;=n)$</li>
<li>$a_{i}^{T}$是矩阵$A$的行向量</li>
<li>向量$x\in R^{n}$是优化变量</li>
</ul>
<p>求解最小二乘问题：</p>
<p>最小二乘问题(1.4)的求解可以化简为求解一组线性方程:</p>
<p>$$(A^{T}A)x=A^{T}b$$</p>
<p>因此，其解析解为$x=(A^{T}A)^{-1}A^{T}b$.</p>
<h1 id="凸集"><a href="#凸集" class="headerlink" title="凸集"></a>凸集</h1><p>仿射集：略</p>
<p>凸集定义：集合$C$被称为凸集，如果$C$中任意两点间的线段任然在$C$中，即对任意$x_{1},x_{2}\ \in C$和满足$0&lt;=\Theta &lt;=1$的$\Theta$都有:</p>
<p>$$\Theta x_{1}\ +\ (1-\Theta)x_{2} \in C$$</p>
<p>粗略地，如果集合中每一点都可以被其他点沿着它们之间一条无阻碍的路径看见，那么这个集合就是凸集。无阻碍是指整条路径都在集合中。</p>
<p>例如：</p>
<p><img src="/images/2019/picture/convex-optimization/1.jpg" alt></p>
<ul>
<li>第一个：是凸集（集合中的任意两点连线的所有点，都在集合中）</li>
<li>第二个：不是凸集，原因图中已经标的很清楚了（有空隙）</li>
<li>第三个：不是凸集，有些边没有在集合中</li>
</ul>
<h1 id="凸函数"><a href="#凸函数" class="headerlink" title="凸函数"></a>凸函数</h1><p>凸函数定义：</p>
<p>函数$f:R^{n}\rightarrow R$是凸的，如果$dom\ f$是凸集，且对于任意$x,y \in dom\ f$和任意$0&lt;=\Theta &lt;=1$，有式(3-1)：</p>
<p>$$f(\Theta x\ +\ (1-\Theta)y)&lt;=\Theta f(x)+(1-\Theta)f(y)$$</p>
<p><img src="/images/2019/picture/convex-optimization/2.png" alt></p>
<p>从几何意义上看，上述不等式意味着点$(x,f(x))$和$(y,f(y))$之间的线段，即$x$到$y$的弦，在函数$f$的上方。如果式(3-1)中的不等式$x≠y$以及$0&lt;\Theta &lt;1$是严格成立，则称$f$是严格凸的。</p>
<p>凸函数的性质:</p>
<p><strong>一阶条件</strong></p>
<p>假设$f$是可微的(即其梯度$\bigtriangledown f$在开集$dom\ f$内处处存在)，则函数$f$是凸函数的充要条件是：</p>
<ul>
<li>(1)$dom\ f$是凸集</li>
<li>(2)对于任意$x,y\in dom\ f$, 该式成立:$f(y)&gt;=f(x)+ \bigtriangledown f(x)^{T}(y-x).$</li>
</ul>
<p><img src="/images/2019/picture/convex-optimization/3.jpg" alt></p>
<p><strong>二阶条件</strong></p>
<p>假设函数$f$是二阶可微的，即对于开集$dom\ f$内的任意一点，它的$Hessian$矩阵或者二阶导数$\bigtriangledown ^{2}f$存在，则函数$f$是凸函数的充要条件是：</p>
<ul>
<li>其$Hessian$矩阵是半正定阵，即对于所有的$x\in dom\ f$,有$\bigtriangledown ^{2}f(x)&gt;=0$.</li>
<li>对于$R$上的函数，上式可以简化为$f^{‘’}(x)&gt;=0$，此条件说明函数$f$的导数是非减的。</li>
</ul>
<p>我们如果能够判断一个函数的海瑟矩阵是正定的，那么我们就可以说这个函数就是凸函数。判断完了凸函数，我们就可以利用凸函数的性质。</p>
<h1 id="凸优化问题"><a href="#凸优化问题" class="headerlink" title="凸优化问题"></a>凸优化问题</h1><p>凸优化问题的标准形式(4.15):</p>
<p>$$minimize\ f_{0}(x)$$<br>$$subject\ to\ f_{i}(x)&lt;=0,\ i=1,…,m$$<br>$$a_{i}^{T}x=b_{i},\ i=1,…,p$$</p>
<p>的问题，其中$f_{0},…,f_{m}$为凸函数，$x^{*}\in X$是可微函数$f_{0}$的最优解，当且仅当:</p>
<p>$$\bigtriangledown f_{0}(x^{<em>})^{T}(y-x^{</em>})&gt;=0,y\in X$$</p>
<h2 id="无约束凸优化的问题"><a href="#无约束凸优化的问题" class="headerlink" title="无约束凸优化的问题"></a>无约束凸优化的问题</h2><h3 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h3><p>无约束凸优化问题(即(4.15)式中，m=p=0),$x^{*}\in X$是可微函数$f$的最优解的重要条件是:</p>
<p>$$\bigtriangledown f(x^{*})=0$$</p>
<h3 id="求解方法"><a href="#求解方法" class="headerlink" title="求解方法"></a>求解方法</h3><p>(1) 解析解</p>
<p>对于少数一些简单的凸优化问题，可以利用最优性准则通过解析来求解。但对于大多数凸优化问题来讲，是没有办法通过解析来求解的。</p>
<p>(2) 下降方法：确定步长、确定搜索方向.</p>
<p><img src="/images/2019/picture/convex-optimization/4.png" alt></p>
<p>(3) 确定步长的方法：固定步长搜索、精确直线搜索、回溯直线搜索<br>(4) 确定搜索方向的方法：梯度下降方法、最速下降方法(一阶泰勒展开近似优化)、牛顿法(二阶泰勒展开近似优化).</p>
<ul>
<li>梯度下降方法必须满足：搜索方向和负梯度成锐角，简单方法是直接用负梯度作为搜索方向，即</li>
</ul>
<p>$$\Delta x=-\bigtriangledown f(x)$$</p>
<ul>
<li>最速下降方法(一阶泰勒展开近似优化)</li>
</ul>
<p><img src="/images/2019/picture/convex-optimization/5.png" alt></p>
<ul>
<li>牛顿法(二阶泰勒展开近似优化)</li>
</ul>
<p><img src="/images/2019/picture/convex-optimization/6.png" alt><br><img src="/images/2019/picture/convex-optimization/7.png" alt><br><img src="/images/2019/picture/convex-optimization/8.png" alt></p>
<h2 id="只含等式约束凸优化的问题"><a href="#只含等式约束凸优化的问题" class="headerlink" title="只含等式约束凸优化的问题"></a>只含等式约束凸优化的问题</h2><h3 id="问题定义-1"><a href="#问题定义-1" class="headerlink" title="问题定义"></a>问题定义</h3><p>考虑只含等式约束而没有不等式约束的问题，即</p>
<p>$$minimize\ f_{0}(x)$$<br>$$subject\ to\ Ax=b,$$</p>
<p>可行解$x$的最优性条件为：对任意满足$Ay=b$的$y$:$\bigtriangledown f_{0}(x)^{T}(y-x)&gt;=0$都成立。</p>
<p>对应的，$x^{*}\in X$是可微函数$f$的最优解的重要条件为，存在$v\in R^{p}$,使得:</p>
<p>$$\bigtriangledown f(x^{*})+A^{T}v=0$$</p>
<p>其中，$A\in R^{p*n}.$</p>
<h3 id="求解方法-1"><a href="#求解方法-1" class="headerlink" title="求解方法"></a>求解方法</h3><p>通过Lagrange对偶问题求解</p>
<h2 id="不等式约束凸优化的问题"><a href="#不等式约束凸优化的问题" class="headerlink" title="不等式约束凸优化的问题"></a>不等式约束凸优化的问题</h2><h3 id="问题定义-2"><a href="#问题定义-2" class="headerlink" title="问题定义"></a>问题定义</h3><p>$$minimize\ f_{0}(x)$$<br>$$subject\ to\ f_{i}(x)&lt;=0,\ i=1,…,m$$<br>$$a_{i}^{T}x=b_{i},\ i=1,…,p$$</p>
<p>其中$f_{0},…,f_{m}$为凸函数。</p>
<h3 id="求解方法-2"><a href="#求解方法-2" class="headerlink" title="求解方法"></a>求解方法</h3><p>通过Lagrange对偶问题求解:</p>
<p>(1) 原始问题</p>
<p><img src="/images/2019/picture/convex-optimization/9.png" alt><br><img src="/images/2019/picture/convex-optimization/10.png" alt><br><img src="/images/2019/picture/convex-optimization/11.png" alt></p>
<p>(2) 对偶问题</p>
<p><img src="/images/2019/picture/convex-optimization/12.png" alt></p>
<p>(3) 原始问题和对偶问题的关系</p>
<p><img src="/images/2019/picture/convex-optimization/13.png" alt><br><img src="/images/2019/picture/convex-optimization/14.png" alt><br><img src="/images/2019/picture/convex-optimization/15.png" alt><br><img src="/images/2019/picture/convex-optimization/16.png" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/26/lightgbm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenxiaolong">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xiaolongc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/26/lightgbm/" itemprop="url">5. lightgbm原理及实战</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-26T22:32:05+08:00">
                2019-11-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">machine learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="lightGBM-简介"><a href="#lightGBM-简介" class="headerlink" title="lightGBM 简介"></a>lightGBM 简介</h1><p>有了 xgboost 这个大杀器之后，为啥要吃饱了撑的又搞个 lightgbm 呢？</p>
<p>今天我们就来聊聊为啥？</p>
<ul>
<li>Gradient-based One-Side Sampling (GOSS, 基于梯度的one-side采样) </li>
<li>Exclusive Feature Bundling (EFB, 和互斥的特征捆绑)</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://blog.csdn.net/shine19930820/article/details/79123216" target="_blank" rel="noopener">论文阅读-LightGBM原理</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/28/Big-data/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenxiaolong">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xiaolongc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/28/Big-data/" itemprop="url">1. Big-data</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-28T22:44:54+08:00">
                2019-10-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/big-data/" itemprop="url" rel="index">
                    <span itemprop="name">big data</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="大数据技术原理与应用（第2版）"><a href="#大数据技术原理与应用（第2版）" class="headerlink" title="大数据技术原理与应用（第2版）"></a>大数据技术原理与应用（第2版）</h1><h1 id="第2章-大数据处理架构-hadoop"><a href="#第2章-大数据处理架构-hadoop" class="headerlink" title="第2章 大数据处理架构 hadoop"></a>第2章 大数据处理架构 hadoop</h1><h2 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1 概述"></a>2.1 概述</h2><p>Hadoop的核心是分布式文件系统（Hadoop Distributed File System，HDFS）和MapReduce。HDFS是针对谷歌文件系统（Google File System，GFS）的开源实现，是面向普通硬件环境的分布式文件系统，具有较高的读写速度、很好的容错性和可伸缩性，支持大规模数据的分布式存储，其冗余数据存储的方式很好地保证了数据的安全性。MapReduce是针对谷歌 MapReduce 的开源实现，允许用户在不了解分布式系统底层细节的情况下开发并行应用程序，采用MapReduce来整合分布式文件系统上的数据，可保证分析和处理数据的高效性。借助于Hadoop，程序员可以轻松地编写分布式并行程序，将其运行于廉价计算机集群上，完成海量数据的存储与计算。</p>
<p>它具有以下几个方面的特性。</p>
<ul>
<li>高可靠性</li>
<li>高效性。</li>
<li>高可扩展性</li>
<li>高容错性</li>
<li>成本低。</li>
<li>运行在Linux平台上。</li>
<li>支持多种编程语言。</li>
</ul>
<h2 id="2-2-Hadoop生态系统"><a href="#2-2-Hadoop生态系统" class="headerlink" title="2.2 Hadoop生态系统"></a>2.2 Hadoop生态系统</h2><p>除了核心的HDFS和MapReduce以外，Hadoop生态系统还包括Zookeeper、HBase、Hive、Pig、Mahout、Sqoop、Flume、Ambari等功能组件。需要说明的是，Hadoop 2.0中新增了一些重要的组件，即HDFS HA和分布式资源调度管理框架YARN等，</p>
<p><img src="/images/2019/picture/Big-data/1.jpeg" alt="Hadoop架构"></p>
<p>Hadoop分布式文件系统（Hadoop Distributed File System，HDFS）是Hadoop项目的两大核心之一，是针对谷歌文件系统（Google File System，GFS）的开源实现。</p>
<p>HBase是一个提供高可靠性、高性能、可伸缩、实时读写、分布式的列式数据库，一般采用HDFS作为其底层数据存储。HBase是针对谷歌BigTable的开源实现，二者都采用了相同的数据模型，具有强大的非结构化数据存储能力。HBase与传统关系数据库的一个重要区别是，前者采用基于列的存储，而后者采用基于行的存储。HBase具有良好的横向扩展能力，可以通过不断增加廉价的商用服务器来增加存储能力。</p>
<p>Hadoop MapReduce是针对谷歌MapReduce的开源实现。MapReduce是一种编程模型，用于大规模数据集（大于1 TB）的并行运算，它将复杂的、运行于大规模集群上的并行计算过程高度地抽象到了两个函数——Map 和 Reduce 上，并且允许用户在不了解分布式系统底层细节的情况下开发并行应用程序，并将其运行于廉价计算机集群上，完成海量数据的处理。</p>
<p>Hive是一个基于Hadoop的数据仓库工具，可以用于对Hadoop文件中的数据集进行数据整理、特殊查询和分析存储。</p>
<p>Pig是一种数据流语言和运行环境，适合于使用Hadoop和MapReduce平台来查询大型半结构化数据集。</p>
<p>Mahout是Apache软件基金会旗下的一个开源项目，提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。</p>
<p>Zookeeper是针对谷歌Chubby的一个开源实现，是高效和可靠的协同工作系统，提供分布式锁之类的基本服务（如统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等），用于构建分布式应用，减轻分布式应用程序所承担的协调任务。</p>
<p>Flume是Cloudera提供的一个高可用的、高可靠的、分布式的海量日志采集、聚合和传输的系统</p>
<p>Sqoop是SQL-to-Hadoop的缩写，主要用来在Hadoop和关系数据库之间交换数据，可以改进数据的互操作性。通过Sqoop可以方便地将数据从MySQL、Oracle、PostgreSQL等关系数据库中导入Hadoop（可以导入HDFS、HBase或Hive），或者将数据从Hadoop导出到关系数据库，使得传统关系数据库和Hadoop之间的数据迁移变得非常方便。</p>
<p>Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的安装、部署、配置和管理。</p>
<p><img src="/images/2019/picture/Big-data/2.jpeg" alt="存储与管理"></p>
<h1 id="第3章-分布式文件系统-HDFS"><a href="#第3章-分布式文件系统-HDFS" class="headerlink" title="第3章 分布式文件系统 HDFS"></a>第3章 分布式文件系统 HDFS</h1><h2 id="3-1-分布式文件系统"><a href="#3-1-分布式文件系统" class="headerlink" title="3.1 分布式文件系统"></a>3.1 分布式文件系统</h2><p>相对于传统的本地文件系统而言，分布式文件系统（Distributed File System）是一种通过网络实现文件在多台主机上进行分布式存储的文件系统。分布式文件系统的设计一般采用“客户机/服务器”（Client/Server）模式，客户端以特定的通信协议通过网络与服务器建立连接，提出文件访问请求，客户端和服务器可以通过设置访问权来限制请求方对底层数据存储块的访问。目前，已得到广泛应用的分布式文件系统主要包括GFS和HDFS等，后者是针对前者的开源实现。</p>
<p>与普通文件系统类似，分布式文件系统也采用了块的概念，文件被分成若干个块进行存储，块是数据读写的基本单元，只不过分布式文件系统的块要比操作系统中的块大很多。比如，HDFS默认的一个块的大小是64 MB。与普通文件不同的是，在分布式文件系统中，如果一个文件小于一个数据块的大小，它并不占用整个数据块的存储空间。</p>
<p>这些节点分为两类：一类叫“主节点”（Master Node），或者也被称为“名称节点”（NameNode）；另一类叫“从节点”（Slave Node），或者也被称为“数据节点”（DataNode）。名称节点负责文件和目录的创建、删除和重命名等，同时管理着数据节点和文件块的映射关系，因此客户端只有访问名称节点才能找到请求的文件块所在的位置，进而到相应位置读取所需文件块。数据节点负责数据的存储和读取，在存储时，由名称节点分配存储位置，然后由客户端把数据直接写入相应数据节点；在读取时，客户端从名称节点获得数据节点和文件块的映射关系，然后就可以到相应位置访问文件块。数据节点也要根据名称节点的命令创建、删除数据块和冗余复制。</p>
<h2 id="3-2-HDFS简介"><a href="#3-2-HDFS简介" class="headerlink" title="3.2 HDFS简介"></a>3.2 HDFS简介</h2><p>总体而言，HDFS要实现以下目标：</p>
<ul>
<li>兼容廉价的硬件设备。</li>
<li>流数据读写。</li>
<li>大数据集。</li>
<li>简单的文件模型。</li>
<li>强大的跨平台兼容性</li>
<li>不适合低延迟数据访问</li>
<li>无法高效存储大量小文件</li>
</ul>
<p>首先，HDFS 采用名称节点（NameNode）来管理文件系统的元数据，这些元数据被保存在内存中，从而使客户端可以快速获取文件实际存储位置。通常，每个文件、目录和块大约占150字节，如果有1 000万个文件，每个文件对应一个块，那么，名称节点至少要消耗3 GB的内存来保存这些元数据信息</p>
<p>不支持多用户写入及任意修改文件。HDFS只允许一个文件有一个写入者，不允许多个用户对同一个文件执行写操作，而且只允许对文件执行追加操作，不能执行随机写操作。</p>
<p><img src="/images/2019/picture/Big-data/3.jpeg" alt="HDFS实现方式"></p>
<h2 id="3-3-HDFS的相关概念"><a href="#3-3-HDFS的相关概念" class="headerlink" title="3.3 HDFS的相关概念"></a>3.3 HDFS的相关概念</h2><p>本节介绍HDFS中的相关概念，包括块、名称节点、数据节点、第二名称节点。</p>
<p>HDFS也同样采用了块的概念，默认的一个块大小是64 MB。在HDFS中的文件会被拆分成多个块，每个块作为独立的单元进行存储。</p>
<p>HDFS这么做的原因，是为了最小化寻址开销。</p>
<p>当客户端需要访问一个文件时，首先从名称节点获得组成这个文件的数据块的位置列表，然后根据位置列表获取实际存储各个数据块的数据节点的位置，最后数据节点根据数据块信息在本地Linux 文件系统中找到对应的文件，并把数据返回给客户端。</p>
<p>块的大小也不宜设置过大，因为，通常MapReduce中的Map任务一次只处理一个块中的数据，如果启动的任务太少，就会降低作业并行处理速度。</p>
<p>在 HDFS 中，名称节点（NameNode）负责管理分布式文件系统的命名空间（Namespace），保存了两个核心的数据结构（见图3-3），即FsImage和EditLog。FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据，操作日志文件EditLog中记录了所有针对文件的创建、删除、重命名等操作。</p>
<p><img src="/images/2019/picture/Big-data/4.jpeg" alt="节点"></p>
<p>名称节点记录了每个文件中各个块所在的数据节点的位置信息，但是并不持久化存储这些信息，而是在系统每次启动时扫描所有数据节点重构得到这些信息</p>
<p>名称节点在启动时，会将 FsImage 的内容加载到内存当中，然后执行 EditLog 文件中的各项操作，使得内存中的元数据保持最新。这个操作完成以后，就会创建一个新的 FsImage 文件和一个空的EditLog文件。名称节点启动成功并进入正常运行状态以后，HDFS中的更新操作都会被写入到 EditLog，而不是直接写入 FsImage，这是因为对于分布式文件系统而言，FsImage文件通常都很庞大（一般都是GB级别以上），如果所有的更新操作都直接往FsImage文件中添加，那么系统就会变得非常缓慢。相对而言，EditLog通常都要远远小于FsImage，更新操作写入到EditLog是非常高效的。名称节点在启动的过程中处于“安全模式”，只能对外提供读操作，无法提供写操作。启动过程结束后，系统就会退出安全模式，进入正常运行状态，对外提供读写操作。</p>
<p>数据节点（DataNode）是分布式文件系统HDFS的工作节点，负责数据的存储和读取，会根据客户端或者名称节点的调度来进行数据的存储和检索，并且向名称节点定期发送自己所存储的块的列表。每个数据节点中的数据会被保存在各自节点的本地Linux文件系统中。</p>
<p>当名称节点重启时，需要将FsImage加载到内存中，然后逐条执行EditLog中的记录，使得FsImage保持最新。可想而知，如果EditLog很大，就会导致整个过程变得非常缓慢，使得名称节点在启动过程中长期处于“安全模式”，无法正常对外提供写操作，影响了用户的使用。</p>
<p>为了有效解决EditLog逐渐变大带来的问题，HDFS在设计中采用了第二名称节点（Secondary NameNode）。第二名称节点是HDFS架构的一个重要组成部分，具有两个方面的功能：首先，可以完成EditLog与FsImage的合并操作，减小EditLog文件大小，缩短名称节点重启时间；其次，可以作为名称节点的“检查点”，保存名称节点中的元数据信息。具体如下。</p>
<ul>
<li>（1）EditLog与FsImage的合并操作。</li>
<li>（2）作为名称节点的“检查点”。</li>
</ul>
<p><img src="/images/2019/picture/Big-data/5.jpeg" alt="节点"></p>
<h2 id="3-4-HDFS体系结构"><a href="#3-4-HDFS体系结构" class="headerlink" title="3.4 HDFS体系结构"></a>3.4 HDFS体系结构</h2><p>本节首先简要介绍HDFS的体系结构，然后介绍HDFS的命名空间管理、通信协议、客户端，最后指出HDFS体系结构的局限性。</p>
<p>HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群包括一个名称节点和若干个数据节点（见图3-5）。名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。集群中的数据节点一般是一个节点运行一个数据节点进程，负责处理文件系统客户端的读/写请求，在名称节点的统一调度下进行数据块的创建、删除和复制等操作。每个数据节点的数据实际上是保存在本地Linux文件系统中的。每个数据节点会周期性地向名称节点发送“心跳”信息，报告自己的状态，没有按时发送心跳信息的数据节点会被标记为“宕机”，不会再给它分配任何I/O请求。</p>
<p><img src="/images/2019/picture/Big-data/6.jpeg" alt="命名空间管理"></p>
<p>HDFS的命名空间包含目录、文件和块。命名空间管理是指命名空间支持对HDFS中的目录、文件和块做类似文件系统的创建、修改、删除等基本操作。在当前的HDFS体系结构中，在整个HDFS 集群中只有一个命名空间，并且只有唯一一个名称节点，该节点负责对这个命名空间进行管理。</p>
<p><img src="/images/2019/picture/Big-data/7.jpeg" alt="读取数据"><br><img src="/images/2019/picture/Big-data/8.jpeg" alt="写入数据"></p>
<p>HDFS是一个部署在集群上的分布式文件系统，因此很多数据需要通过网络进行传输。所有的HDFS通信协议都是构建在TCP/IP协议基础之上的。客户端通过一个可配置的端口向名称节点主动发起TCP连接，并使用客户端协议与名称节点进行交互。名称节点和数据节点之间则使用数据节点协议进行交互。客户端与数据节点的交互是通过 RPC（Remote Procedure Call）来实现的。在设计上，名称节点不会主动发起RPC，而是响应来自客户端和数据节点的RPC请求。</p>
<p>明显的局限性</p>
<ul>
<li>（1）命名空间的限制。名称节点是保存在内存中的，因此名称节点能够容纳对象（文件、块）的个数会受到内存空间大小的限制。</li>
<li>（2）性能的瓶颈</li>
<li>（3）隔离问题。</li>
<li>（4）集群的可用性</li>
</ul>
<h2 id="3-5-HDFS的存储原理"><a href="#3-5-HDFS的存储原理" class="headerlink" title="3.5 HDFS的存储原理"></a>3.5 HDFS的存储原理</h2><p>本节介绍HDFS的存储原理，包括数据的冗余存储、数据存取策略、数据错误与恢复。</p>
<ul>
<li>1.数据存放为了提高数据的可靠性与系统的可用性，以及充分利用网络带宽，HDFS采用了以机架（Rack）为基础的数据存放策略。HDFS 默认的冗余复制因子是 3，每一个文件块会被同时保存到 3 个地方，其中，有两份副本放在同一个机架的不同机器上面，第三个副本放在不同机架的机器上面，这样既可以保证机架发生异常时的数据恢复，也可以提高数据读写性能。 </li>
<li>2.数据读取HDFS提供了一个API可以确定一个数据节点所属的机架ID，客户端也可以调用API获取自己所属的机架ID</li>
<li>3.数据复制HDFS的数据复制采用了流水线复制的策略，大大提高了数据复制过程的效率。</li>
</ul>
<p>HDFS具有较高的容错性，可以兼容廉价的硬件，它把硬件出错看成一种常态，而不是异常，并设计了相应的机制检测数据错误和进行自动恢复，主要包括以下3种情形。</p>
<p>(1).名称节点出错</p>
<p>Hadoop采用两种机制来确保名称节点的安全：第一，把名称节点上的元数据信息同步存储到其他文件系统（比如远程挂载的网络文件系统NFS）中；第二，运行一个第二名称节点，当名称节点宕机以后，可以把第二名称节点作为一种弥补措施，利用第二名称节点中的元数据信息进行系统恢复，但是从前面对第二名称节点的介绍中可以看出，这样做仍然会丢失部分数据。</p>
<p>(2).数据节点出错</p>
<p>每个数据节点会定期向名称节点发送“心跳”信息，向名称节点报告自己的状态。当数据节点发生故障，或者网络发生断网时，名称节点就无法收到来自一些数据节点的“心跳”信息，这时这些数据节点就会被标记为“宕机”，节点上面的所有数据都会被标记为“不可读”，名称节点不会再给它们发送任何I/O请求</p>
<p>(3).数据出错</p>
<p>客户端在读取到数据后，会采用md5和sha1对数据块进行校验，以确定读取到正确的数据。</p>
<h2 id="3-7-HDFS编程实践"><a href="#3-7-HDFS编程实践" class="headerlink" title="3.7 HDFS编程实践"></a>3.7 HDFS编程实践</h2><p>关于HDFS的Shell命令有一个统一的格式。hadoop command [genericOptions][commandOptions]<br>HDFS有很多命令，其中fs命令可以说是HDFS最常用的命令，利用fs命令可以查看HDFS文件系统的目录结构、上传和下载数据、创建文件等。该命令的用法如下。hadoop fs [genericOptions][commandOptions]</p>
<h1 id="第三篇-大数据处理与分析"><a href="#第三篇-大数据处理与分析" class="headerlink" title="第三篇 大数据处理与分析"></a>第三篇 大数据处理与分析</h1><p>分布式并行编程框架MapReduce可以大幅提高程序性能，实现高效的批量数据处理。基于内存的分布式计算框架 Spark，是一个可应用于大规模数据处理的快速、通用引擎</p>
<p>流计算框架Storm是一个低延迟、可扩展、高可靠的处理引擎</p>
<p>大数据中包括很多图结构数据，但是MapReduce不适合用来解决大规模图计算问题，因此新的图计算框架应运而生，Pregel 就是其中一种具有代表性的产品</p>
<p><img src="/images/2019/picture/Big-data/11.jpeg" alt="写入数据"></p>
<h2 id="第7章-MapReduce"><a href="#第7章-MapReduce" class="headerlink" title="第7章 MapReduce"></a>第7章 MapReduce</h2><p>大数据时代除了需要解决大规模数据的高效存储问题，还需要解决大规模数据的高效处理问题。</p>
<p>MapReduce是一种并行编程模型，用于大规模数据集（大于1 TB）的并行运算，它将复杂的、运行于大规模集群上的并行计算过程高度抽象到两个函数：Map 和 Reduce。</p>
<h2 id="7-1-概述"><a href="#7-1-概述" class="headerlink" title="7.1 概述"></a>7.1 概述</h2><p>MapReduce以及它的核心函数Map和Reduce。</p>
<p>谷歌公司最先提出了分布式并行编程模型MapReduce，Hadoop MapReduce是它的开源实现。谷歌的MapReduce运行在分布式文件系统GFS上，与谷歌类似，Hadoop MapReduce运行在分布式文件系统HDFS上。</p>
<p>谷歌在2003年～2006年连续发表了3篇很有影响力的文章，分别阐述了GFS、MapReduce和BigTable的核心思想。其中，MapReduce是谷歌公司的核心计算模型。MapReduce将复杂的、运行于大规模集群上的并行计算过程高度地抽象到两个函数：Map和Reduce，这两个函数及其核心思想都源自函数式编程语言。</p>
<p>在MapReduce中，一个存储在分布式文件系统中的大规模数据集会被切分成许多独立的小数据块，这些小数据块可以被多个Map任务并行处理。MapReduce框架会为每个Map任务输入一个数据子集，Map任务生成的结果会继续作为Reduce任务的输入，最终由Reduce任务输出最后结果，并写入分布式文件系统。特别需要注意的是，适合用MapReduce来处理的数据集需要满足一个前提条件：待处理的数据集可以分解成许多小的数据集，而且每一个小数据集都可以完全并行地进行处理。</p>
<p>MapReduce编程之所以比较容易，是因为程序员只要关注如何实现Map和Reduce函数，而不需要处理并行编程中的其他各种复杂问题，如分布式存储、工作调度、负载均衡、容错处理、网络通信等，这些问题都会由MapReduce框架负责处理。</p>
<p>Map函数和Reduce函数都是以作为输入，按一定的映射规则转换成另一个或一批进行输出（见表7-1）</p>
<p><img src="/images/2019/picture/Big-data/12.jpeg" alt="写入数据"></p>
<h2 id="7-2-MapReduce的工作流程"><a href="#7-2-MapReduce的工作流程" class="headerlink" title="7.2 MapReduce的工作流程"></a>7.2 MapReduce的工作流程</h2><p>理解MapReduce的工作流程，是开展MapReduce编程的前提。本节首先给出工作流程概述，并阐述MapReduce的各个执行阶段，最后对MapReduce的核心环节——Shuffle过程进行详细剖析。</p>
<p>大规模数据集的处理包括分布式存储和分布式计算两个核心环节</p>
<p>MapReduce的核心思想可以用“分而治之”来描述，如图7-1所示，也就是把一个大的数据集拆分成多个小数据块在多台机器上并行处理，也就是说，一个大的MapReduce作业，首先会被拆分成许多个Map任务在多台机器上并行执行，每个Map任务通常运行在数据存储的节点上，这样，计算和数据就可以放在一起运行，不需要额外的数据传输开销。当Map任务结束后，会生成以形式表示的许多中间结果。然后，这些中间结果会被分发到多个Reduce任务在多台机器上并行执行，具有相同key的会被发送到同一个Reduce任务那里，Reduce任务会对中间结果进行汇总计算得到最后结果，并输出到分布式文件系统中。</p>
<p><img src="/images/2019/picture/Big-data/13.jpeg" alt="MapReduce的工作流程"> </p>
<p>需要指出的是，不同的Map任务之间不会进行通信，不同的Reduce任务之间也不会发生任何信息交换；用户不能显式地从一台机器向另一台机器发送消息，所有的数据交换都是通过MapReduce框架自身去实现的。</p>
<p>为了让Reduce可以并行处理Map的结果，需要对Map的输出进行一定的分区（Portition）、排序（Sort）、合并（Combine）、归并（Merge）等操作，得到形式的中间结果，再交给对应的 Reduce 进行处理，这个过程称为 Shuffle。从无序的到有序的，这个过程用Shuffle（洗牌）来称呼是非常形象的。</p>
<p><img src="/images/2019/picture/Big-data/14.jpeg" alt="Shuffle过程"> </p>
<p>所谓Shuffle，是指对Map输出结果进行分区、排序、合并等处理并交给Reduce的过程。因此，Shuffle过程分为Map端的操作和Reduce端的操作，如图7-3所示，主要执行以下操作</p>
<p><img src="/images/2019/picture/Big-data/15.jpeg" alt="Shuffle过程">  </p>
<p>在Map端的Shuffle过程Map的输出结果首先被写入缓存，当缓存满时，就启动溢写操作，把缓存中的数据写入磁盘文件，并清空缓存。当启动溢写操作时，首先需要把缓存中的数据进行分区，然后对每个分区的数据进行排序（Sort）和合并（Combine），之后再写入磁盘文件。每次溢写操作会生成一个新的磁盘文件，随着Map任务的执行，磁盘中就会生成多个溢写文件。在Map任务全部结束之前，这些溢写文件会被归并（Merge）成一个大的磁盘文件，然后通知相应的Reduce任务来领取属于自己处理的数据。（2）在Reduce端的Shuffle过程Reduce任务从Map端的不同Map机器领回属于自己处理的那部分数据，然后对数据进行归并（Merge）后交给Reduce处理。</p>
<p><strong> 2.Map 端的Shuffle过程 </strong> </p>
<ul>
<li>（1）输入数据和执行Map任务</li>
<li>（2）写入缓存</li>
<li>（3）溢写（分区、排序和合并）。并非所有场合都可以使用Combiner，因为Combiner的输出是Reduce任务的输入，Combiner绝不能改变Reduce任务最终的计算结果，一般而言，累加、最大值等场景可以使用合并操作。经过分区、排序以及可能发生的合并操作之后，这些缓存中的键值对就可以被写入磁盘，并清空缓存。每次溢写操作都会在磁盘中生成一个新的溢写文件，写入溢写文件中的所有键值对都是经过分区和排序的。</li>
<li>（4）文件归并每次溢写操作都会在磁盘中生成一个新的溢写文件，随着MapReduce任务的进行，磁盘中的溢写文件数量会越来越多。当然，如果Map输出结果很少，磁盘上只会存在一个溢写文件，但是通常都会存在多个溢写文件。最终，在Map任务全部结束之前，系统会对所有溢写文件中的数据进行归并（Merge），生成一个大的溢写文件，这个大的溢写文件中的所有键值对也是经过分区和排序的。</li>
</ul>
<p>所谓“归并”，是指对于具有相同key的键值对会被归并成一个新的键值对。具体而言，对于若干个具有相同 key 的键值对， …… 会被归并成一个新的键值对&gt;。</p>
<p><img src="/images/2019/picture/Big-data/16.jpeg" alt="Shuffle过程">  </p>
<p>经过上述4个步骤以后，Map端的Shuffle过程全部完成，最终生成的一个大文件会被存放在本地磁盘上。这个大文件中的数据是被分区的，不同的分区会被发送到不同的Reduce任务进行并行处理。JobTracker会一直监测Map任务的执行，当监测到一个Map任务完成后，就会立即通知相关的Reduce任务来“领取”数据，然后开始Reduce端的Shuffle过程。</p>
<p><strong> 3.Reduce端的Shuffle过程 </strong></p>
<p>Reduce端的Shuffle过程非常简单，只需要从Map端读取Map结果，然后执行归并操作，最后输送给Reduce任务进行处理。具体而言，Reduce端的Shuffle过程包括3个步骤，如图7-5所示。</p>
<ul>
<li>（1）“领取”数据</li>
</ul>
<p>Map端的Shuffle过程结束后，所有Map输出结果都保存在Map机器的本地磁盘上，Reduce任务需要把这些数据“领取”（Fetch）回来存放到自己所在机器的本地磁盘上。因此，在每个Reduce任务真正开始之前，它大部分时间都在从Map端把属于自己处理的那些分区的数据“领取”过来。每个Reduce任务会不断地通过RPC向JobTracker询问Map任务是否已经完成；JobTracker监测到一个Map任务完成后，就会通知相关的Reduce任务来“领取”数据；一旦一个Reduce任务收到JobTracker的通知，它就会到该Map任务所在机器上把属于自己处理的分区数据领取到本地磁盘中。一般系统中会存在多个Map机器，因此Reduce任务会使用多个线程同时从多个Map机器领回数据。</p>
<ul>
<li>（2）归并数据</li>
</ul>
<p>从Map端领回的数据会首先被存放在Reduce任务所在机器的缓存中，如果缓存被占满，就会像Map端一样被溢写到磁盘中。</p>
<p>当溢写过程启动时，具有相同key的键值对会被归并（Merge），如果用户定义了Combiner，则归并后的数据还可以执行合并操作，减少写入磁盘的数据量</p>
<p>最终，当所有的 Map 端数据都已经被领回时，和 Map端类似，多个溢写文件会被归并成一个大文件，归并的时候还会对键值对进行排序，从而使得最终大文件中的键值对都是有序的</p>
<p>假设磁盘中生成了50个溢写文件，每轮可以归并10个溢写文件，则需要经过5轮归并，得到5个归并后的大文件。</p>
<ul>
<li>（3）把数据输入给Reduce任务</li>
</ul>
<p><img src="/images/2019/picture/Big-data/17.jpeg" alt="Shuffle过程"> </p>
<p>磁盘中经过多轮归并后得到的若干个大文件，不会继续归并成一个新的大文件，而是直接输入给Reduce任务，这样可以减少磁盘读写开销。由此，整个Shuffle过程顺利结束。接下来，Reduce任务会执行 Reduce 函数中定义的各种映射，输出最终结果，并保存到分布式文件系统中（比如GFS或HDFS）。</p>
<h2 id="7-3-实例分析：WordCount"><a href="#7-3-实例分析：WordCount" class="headerlink" title="7.3 实例分析：WordCount"></a>7.3 实例分析：WordCount</h2><p>首先，需要检查WordCount程序任务是否可以采用MapReduce来实现。</p>
<p>MapReduce来处理的数据集需要满足一个前提条件：待处理的数据集可以分解成许多小的数据集，而且每一个小数据集都可以完全并行地进行处理。</p>
<h2 id="7-6-本章小结"><a href="#7-6-本章小结" class="headerlink" title="7.6 本章小结"></a>7.6 本章小结</h2><p>MapReduce 执行的全过程包括以下几个主要阶段：从分布式文件系统读入数据、执行 Map任务输出中间结果、通过Shuffle阶段把中间结果分区排序整理后发送给Reduce任务、执行Reduce任务得到最终结果并写入分布式文件系统。在这几个阶段中，Shuffle阶段非常关键，必须深刻理解这个阶段的详细执行过程。</p>
<p><img src="/images/2019/picture/Big-data/18.jpeg" alt="Shuffle过程"> </p>
<h1 id="第8章-hadoop-再讨论"><a href="#第8章-hadoop-再讨论" class="headerlink" title="第8章 hadoop 再讨论"></a>第8章 hadoop 再讨论</h1><h2 id="8-1-Hadoop的优化与发展"><a href="#8-1-Hadoop的优化与发展" class="headerlink" title="8.1 Hadoop的优化与发展"></a>8.1 Hadoop的优化与发展</h2><p>Hadoop1.0的核心组件（仅指MapReduce和HDFS，不包括Hadoop生态系统内的Pig、Hive、HBase等其他组件）主要存在以下不足。</p>
<p>在后续发展过程中，Hadoop对MapReduce和HDFS的许多方面做了有针对性的改进提升（见表8-1），同时在Hadoop生态系统中也融入了更多的新成员，使得Hadoop功能更加完善，比较有代表性的产品包括Pig、Oozie、Tez、Kafka等（见表8-2）。</p>
<p><img src="/images/2019/picture/Big-data/19.jpeg" alt="HDFS进化"><br><img src="/images/2019/picture/Big-data/20.jpeg" alt="HDFS进化"> </p>
<h2 id="8-2-HDFS2-0的新特性"><a href="#8-2-HDFS2-0的新特性" class="headerlink" title="8.2 HDFS2.0的新特性"></a>8.2 HDFS2.0的新特性</h2><p>在HDFS1.0中，只存在一个名称节点，这就是常说的“单点故障问题”</p>
<p>为了解决单点故障问题，HDFS2.0采用了HA（High Availability）架构。</p>
<p>在一个典型的HA集群中，一般设置两个名称节点，其中一个名称节点处于“活跃（Active）”状态，另一个处于“待命（Standby）”状态，如图8-1所示。</p>
<p><img src="/images/2019/picture/Big-data/21.jpeg" alt="名称节点"> </p>
<p>由于待命名称节点是活跃名称节点的“热备份”，因此活跃名称节点的状态信息必须实时同步到待命名称节点。</p>
<p>两种名称节点的状态同步，可以借助于一个共享存储系统来实现，比如 NFS （Network File System）、QJM（Quorum Journal Manager）或者Zookeeper。</p>
<p>Zookeeper可以确保任意时刻只有一个名称节点提供对外服务</p>
<p>HDFS1.0采用单名称节点的设计，不仅会带来单点故障问题，还存在可扩展性、性能和隔离性等问题</p>
<p>HDFS1.0中只有一个名称节点，不可以水平扩展，而单个名称节点的内存空间是有上限的，这限制了系统中数据块、文件和目录的数目。是否可以通过纵向扩展的方式（即为单个名称节点增加更多的CPU、内存等资源）解决这个问题呢？答案是否定的。</p>
<p>HDFS HA在本质上还是单名称节点，只是通过“热备份”设计方式解决了单点故障问题，并没有解决可扩展性、系统性能和隔离性三个方面的问题。</p>
<p>HDFS 联邦可以很好地解决上述三个方面的问题。</p>
<p>HDFS 联邦并不是真正的分布式设计，但是采用这种简单的“联合”设计方式，在实现和管理复杂性方面，都要远低于真正的分布式设计，而且可以快速满足需求。</p>
<p>在 HDFS 联邦中，所有名称节点会共享底层的数据节点存储资源，如图 8-2 所示。每个数据节点要向集群中所有的名称节点注册，并周期性地向名称节点发送“心跳”和块信息，报告自己的状态，同时也会处理来自名称节点的指令。</p>
<p>HDFS1.0不同的是，HDFS 联邦拥有多个独立的命名空间，其中，每一个命名空间管理属于自己的一组块，这些属于同一个命名空间的块构成一个“块池”（Block Pool）。每个数据节点会为多个块池提供块的存储。可以看出，数据节点是一个物理概念，而块池则属于逻辑概念，一个块池是一组块的逻辑集合，块池中的各个块实际上是存储在各个不同的数据节点中的。因此，HDFS 联邦中的一个名称节点失效，也不会影响到与它相关的数据节点继续为其他名称节点提供服务。</p>
<p>对于HDFS联邦中的多个命名空间，可以采用客户端挂载表（Client Side Mount Table）方式进行数据共享和访问。</p>
<p>客户可以访问不同的挂载点来访问不同的子命名空间。这就是 HDFS 联邦中命名空间管理的基本原理，即把各个命名空间挂载到全局“挂载表”（Mount-table）中，实现数据全局共享；</p>
<h2 id="8-3-新一代资源管理调度框架YARN"><a href="#8-3-新一代资源管理调度框架YARN" class="headerlink" title="8.3 新一代资源管理调度框架YARN"></a>8.3 新一代资源管理调度框架YARN</h2><p>MapReduce1.0 采用 Master/Slave 架构设计（见图 8-4），包括一个 JobTracker 和若干个TaskTracker，前者负责作业的调度和资源的管理，后者负责执行JobTracker指派的具体任务</p>
<p><img src="/images/2019/picture/Big-data/22.jpeg" alt="架构设计"> </p>
<ul>
<li>（1）存在单点故障。</li>
<li>（2）JobTracker“大包大揽”导致任务过重。</li>
<li>（3）容易出现内存溢出。</li>
<li>（4）资源划分不合理。</li>
</ul>
<p>资源（CPU、内存）被强制等量划分成多个“槽”（Slot），槽又被进一步划分为Map槽和Reduce槽两种，分别供Map任务和Reduce任务使用，彼此之间不能使用分配给对方的槽，也就是说，当Map任务已经用完Map槽时，即使系统中还有大量剩余的Reduce槽，也不能拿来运行Map任务，反之亦然</p>
<p>为了克服 MapReduce1.0 版本的缺陷，Hadoop2.0 以后的版本对其核心子项目 MapReduce1.0的体系结构进行了重新设计，生成了MapReduce2.0和YARN（Yet Another Resource Negotiator）。</p>
<p>YARN架构设计思路如图8-5所示，基本思路就是“放权”，即不让JobTracker这一个组件承担过多的功能，把原JobTracker三大功能（资源管理、任务调度和任务监控）进行拆分，分别交给不同的新组件去处理。重新设计后得到的 YARN 包括 ResourceManager、ApplicationMaster 和NodeManager，其中，由ResourceManager负责资源管理，由ApplicationMaster负责任务调度和监控，由 NodeManager 负责执行原 TaskTracker 的任务。通过这种“放权”的设计，大大降低了JobTracker的负担，提升了系统运行的效率和稳定性。</p>
<p><img src="/images/2019/picture/Big-data/23.jpeg" alt="架构设计"> </p>
<p>在Hadoop1.0中，其核心子项目MapReduce1.0既是一个计算框架，也是一个资源管理调度框架。到了Hadoop2.0以后，MapReduce1.0中的资源管理调度功能被单独分离出来形成了YARN，它是一个纯粹的资源管理调度框架，而不是一个计算框架；而被剥离了资源管理调度功能的MapReduce 框架就变成了MapReduce2.0，它是运行在YARN之上的一个纯粹的计算框架，不再自己负责资源调度管理服务，而是由YARN为其提供资源管理调度服务。</p>
<p>如图8-6所示，YARN体系结构中包含了三个组件：ResourceManager、ApplicationMaster和NodeManager。YARN各个组件的功能见表8-3。</p>
<p><img src="/images/2019/picture/Big-data/24.jpeg" alt="架构设计"> </p>
<p>ResourceManager（RM）是一个全局的资源管理器，负责整个系统的资源管理和分配，主要包括两个组件，即调度器（Scheduler）和应用程序管理器（Applications Manager）</p>
<p>调度器主要负责资源管理和分配，不再负责跟踪和监控应用程序的执行状态，也不负责执行失败恢复，因为这些任务都已经交给ApplicationMaster组件来负责。</p>
<p>调度器接收来自ApplicationMaster的应用程序资源请求，并根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），把集群中的资源以“容器”的形式分配给提出申请的应用程序，容器的选择通常会考虑应用程序所要处理的数据的位置，进行就近选择，从而实现“计算向数据靠拢”。</p>
<p>而在 YARN 中是以容器（Container）作为动态资源分配单位，每个容器中都封装了一定数量的CPU、内存、磁盘等资源，从而限定每个应用程序可以使用的资源量</p>
<p><img src="/images/2019/picture/Big-data/25.jpeg" alt="架构设计"> </p>
<p>在Hadoop平台上，用户的应用程序是以作业（Job）的形式提交的，然后一个作业会被分解成多个任务（包括Map任务和Reduce任务）进行分布式执行。</p>
<p>ApplicationMaster。ApplicationMaster 的主要功能是：（1）当用户作业提交时，ApplicationMaster 与 ResourceManager 协商获取资源，ResourceManager 会以容器的形式为ApplicationMaster分配资源；（2）把获得的资源进一步分配给内部的各个任务（Map任务或Reduce任务），实现资源的“二次分配”；（3）与NodeManager保持交互通信进行应用程序的启动、运行、监控和停止，监控申请到的资源的使用情况，对所有任务的执行进度和状态进行监控，并在任务发生失败时执行失败恢复（即重新申请资源重启任务）；（4）定时向ResourceManager发送“心跳”消息，报告资源的使用情况和应用的进度信息；（5）当作业完成时，ApplicationMaster 向ResourceManager注销容器，执行周期完成。</p>
<p><img src="/images/2019/picture/Big-data/26.jpeg" alt="架构设计"> </p>
<p>NodeManager是驻留在一个YARN集群中的每个节点上的代理，主要负责容器生命周期管理，监控每个容器的资源（CPU、内存等）使用情况，跟踪节点健康状况，并以“心跳”的方式与ResourceManager保持通信，向ResourceManager汇报作业的资源使用情况和每个容器的运行状态，同时，它还要接收来自 ApplicationMaster 的启动/停止容器的各种请求</p>
<p>在集群部署方面，YARN 的各个组件是和 Hadoop 集群中的其他组件进行统一部署的</p>
<p>YARN的ResourceManager组件和HDFS的名称节点（NameNode）部署在一个节点上，YARN的ApplicationMaster及NodeManager是和HDFS的数据节点（DataNode）部署在一起的。YARN中的容器代表了CPU、内存、网络等计算资源，它也是和HDFS的数据节点一起的。</p>
<h3 id="8-3-4-YARN工作流程"><a href="#8-3-4-YARN工作流程" class="headerlink" title="8.3.4 YARN工作流程"></a>8.3.4 YARN工作流程</h3><p>YARN的工作流程如图8-8所示，在YARN框架中执行一个MapReduce程序时，从提交到完成需要经历如下8个步骤。① 用户编写客户端应用程序，向 YARN 提交应用程序，提交的内容包括 ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。② YARN中的ResourceManager负责接收和处理来自客户端的请求。接到客户端应用程序请求后，ResourceManager里面的调度器会为应用程序分配一个容器。同时，ResourceManager的应用程序管理器会与该容器所在的 NodeManager 通信，为该应用程序在该容器中启动一个ApplicationMaster（即图8-8中的“MR App Mstr”）。③ ApplicationMaster 被创建后会首先向 ResourceManager 注册，从而使得用户可以通过ResourceManager 来直接查看应用程序的运行状态。接下来的步骤 4～7 是具体的应用程序执行步骤。④ ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请资源。⑤ ResourceManager 以“容器”的形式向提出申请的 ApplicationMaster 分配资源，一旦ApplicationMaster 申请到资源后，就会与该容器所在的 NodeManager 进行通信，要求它启动任务。⑥ 当ApplicationMaster要求容器启动任务时，它会为任务设置好运行环境（包括环境变量、JAR 包、二进制程序等），然后将任务启动命令写到一个脚本中，最后通过在容器中运行该脚本来启动任务。⑦ 各个任务通过某个 RPC 协议向 ApplicationMaster 汇报自己的状态和进度，让ApplicationMaster可以随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。⑧ 应用程序运行完成后，ApplicationMaster向ResourceManager的应用程序管理器注销并关闭自己。若 ApplicationMaster 因故失败，ResourceManager 中的应用程序管理器会监测到失败的情形，然后将其重新启动，直到所有的任务执行完毕。</p>
<p><img src="/images/2019/picture/Big-data/27.jpeg" alt="架构设计">  </p>
<h3 id="8-3-5-YARN框架与MapReduce1-0框架的对比分析"><a href="#8-3-5-YARN框架与MapReduce1-0框架的对比分析" class="headerlink" title="8.3.5 YARN框架与MapReduce1.0框架的对比分析"></a>8.3.5 YARN框架与MapReduce1.0框架的对比分析</h3><p>而 YARN 则是一个纯粹的资源调度管理框架，在它上面可以运行包括 MapReduce 在内的不同类型的计算框架，默认类型是MapReduce</p>
<p>YARN 有着更加“宏伟”的发展构想，即发展成为集群中统一的资源管理调度框架，在一个集群中为上层的各种计算框架提供统一的资源管理调度服务。</p>
<h2 id="8-4-Hadoop生态系统中具有代表性的功能组件"><a href="#8-4-Hadoop生态系统中具有代表性的功能组件" class="headerlink" title="8.4 Hadoop生态系统中具有代表性的功能组件"></a>8.4 Hadoop生态系统中具有代表性的功能组件</h2><p>Pig通常用于 ETL（Extraction、Transformation、Loading）过程，即来自各个不同数据源的数据被收集过来以后，采用Pig进行统一加工处理，然后加载到数据仓库Hive中，由Hive实现对海量数据的分析。</p>
<p>图8-11中，group by和join操作都“跨越”了Map和Reduce两个阶段，这是因为，group by和join操作都涉及到Shuffle过程，根据“第7章MapReduce”可以知道，Shuffle过程包含了Map端和Reduce端，所以图中表示group by和join操作的矩形框与Map和Reduce两个阶段都存在重叠区域。</p>
<p><img src="/images/2019/picture/Big-data/28.jpeg" alt="架构设计">  </p>
<p>因此Tez框架可以发挥重要的作用。可以让 Tez 框架运行在 YARN 框架之上，如图 8-13所示，然后让MapReduce、Pig和Hive等计算框架运行在 Tez 框架之上，从而借助于 Tez 框架实现对MapReduce、Pig和Hive等的性能优化，更好地解决现有MapReduce框架在迭代计算（如PageRank计算）和交互式计算方面存在的问题。</p>
<p><img src="/images/2019/picture/Big-data/29.jpeg" alt="架构设计"></p>
<p>Kafka是由LinkedIn公司开发的一种高吞吐量的分布式发布订阅消息系统，用户通过Kafka系统可以发布大量的消息，同时也能实时订阅消费消息。Kafka 设计的初衷是构建一个可以处理海量日志、用户行为和网站运营统计等的数据处理框架。为了满足上述应用需求，就需要同时提供实时在线处理的低延迟和批量离线处理的高吞吐量。</p>
<p>其他工具加入大数据生态系统后，只需要开发和这款通用工具的数据交换方案，就可以通过这个交换枢纽轻松实现和其他Hadoop组件的数据交换。Kafka就是一款可以实现这种功能的产品。</p>
<p>在公司的大数据生态系统中，可以把Kafka作为数据交换枢纽，不同类型的分布式系统（如关系数据库、NoSQL数据库、流处理系统、批处理系统等）可以统一接入Kafka，如图8-14所示，实现和Hadoop各个组件之间的不同类型数据的实时高效交换，较好地满足各种企业的应用需求</p>
<p><img src="/images/2019/picture/Big-data/31.jpeg" alt="架构设计"></p>
<h1 id="第9章-Spark"><a href="#第9章-Spark" class="headerlink" title="第9章 Spark"></a>第9章 Spark</h1><p>而为了使编写程序更为容易，Spark使用简练、优雅的Scala语言编写，基于Scala提供了交互式的编程体验。</p>
<h2 id="9-1-概述"><a href="#9-1-概述" class="headerlink" title="9.1 概述"></a>9.1 概述</h2><p>Spark具有如下4个主要特点。</p>
<ul>
<li>① 运行速度快。Spark使用先进的DAG（Directed Acyclic Graph，有向无环图）执行引擎，以支持循环数据流与内存计算，基于内存的执行速度可比Hadoop MapReduce快上百倍，基于磁盘的执行速度也能快十倍。</li>
</ul>
<p><img src="/images/2019/picture/Big-data/32.jpeg" alt="架构设计"></p>
<ul>
<li>② 容易使用。Spark支持使用Scala、Java、Python和R语言进行编程，简洁的API设计有助于用户轻松构建并行程序，并且可以通过Spark Shell进行交互式编程。</li>
<li>③ 通用性。Spark提供了完整而强大的技术栈，包括SQL查询、流式计算、机器学习和图算法组件，这些组件可以无缝整合在同一个应用中，足以应对复杂的计算。</li>
<li>④ 运行模式多样。Spark可运行于独立的集群模式中，或者运行于Hadoop中，也可运行于Amazon EC2等云环境中，并且可以访问HDFS、Cassandra、HBase、Hive等多种数据源。</li>
</ul>
<p>scala 优势：</p>
<ul>
<li>① Scala具备强大的并发性</li>
<li>② Scala语法简洁，</li>
<li>③ Scala兼容Java，</li>
</ul>
<p>spark 优势： </p>
<ul>
<li>① Spark的计算模式也属于MapReduce，但不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比MapReduce更灵活。</li>
<li>② Spark提供了内存计算，中间结果直接放到内存中，带来了更高的迭代运算效率。</li>
<li>③ Spark基于DAG的任务调度执行机制，要优于MapReduce的迭代执行机制。</li>
</ul>
<h2 id="9-2-Spark生态系统"><a href="#9-2-Spark生态系统" class="headerlink" title="9.2 Spark生态系统"></a>9.2 Spark生态系统</h2><p>Spark 的设计遵循“一个软件栈满足不同应用场景”的理念，逐渐形成了一套完整的生态系统，既能够提供内存计算框架，也可以支持SQL即席查询、实时流式计算、机器学习和图计算等。Spark可以部署在资源管理器YARN之上，提供一站式的大数据解决方案。</p>
<p><img src="/images/2019/picture/Big-data/33.jpeg" alt="架构设计"></p>
<h2 id="9-3-Spark运行架构"><a href="#9-3-Spark运行架构" class="headerlink" title="9.3 Spark运行架构"></a>9.3 Spark运行架构</h2><p>本节首先介绍Spark的基本概念和架构设计方法，然后介绍Spark运行基本流程，最后介绍RDD的运行原理。</p>
<h3 id="9-3-1-基本概念"><a href="#9-3-1-基本概念" class="headerlink" title="9.3.1 基本概念"></a>9.3.1 基本概念</h3><p>在具体讲解Spark运行架构之前，需要先了解以下7个重要的概念。① RDD：是弹性分布式数据集（Resilient Distributed Dataset）的英文缩写，是分布式内存的一个抽象概念，提供了一种高度受限的共享内存模型。② DAG：是Directed Acyclic Graph（有向无环图）的英文缩写，反映RDD之间的依赖关系。③ Executor：是运行在工作节点（Worker Node）上的一个进程，负责运行任务，并为应用程序存储数据。④ 应用：用户编写的Spark应用程序。⑤ 任务：运行在Executor上的工作单元。⑥ 作业：一个作业包含多个RDD及作用于相应RDD上的各种操作。⑦ 阶段：是作业的基本调度单位，一个作业会分为多组任务，每组任务被称为“阶段”，或者也被称为“任务集”。</p>
<p>Spark运行架构如图9-5所示，包括集群资源管理器（Cluster Manager）、运行作业任务的工作节点（Worker Node）、每个应用的任务控制节点（Driver）和每个工作节点上负责具体任务的执行进程（Executor）。</p>
<p><img src="/images/2019/picture/Big-data/34.jpeg" alt="架构设计"> </p>
<p>与Hadoop MapReduce计算框架相比，Spark所采用的Executor有两个优点：一是利用多线程来执行具体的任务（Hadoop MapReduce采用的是进程模型），减少任务的启动开销；二是Executor中有一个BlockManager存储模块，会将内存和磁盘共同作为存储设备，当需要多轮迭代计算时，可以将中间结果存储到这个存储模块里，下次需要时就可以直接读该存储模块里的数据，而不需要读写到HDFS等文件系统里，因而有效减少了IO开销；或者在交互式查询场景下，预先将表缓存到该存储系统上，从而可以提高读写IO性能。</p>
<p><img src="/images/2019/picture/Big-data/35.jpeg" alt="架构设计"> </p>
<p>Spark运行基本流程如图9-7 所示，流程如下。（1）当一个Spark应用被提交时，首先需要为这个应用构建起基本的运行环境，即由任务控制节点（Driver）创建一个SparkContext，由SparkContext负责和资源管理器（Cluster Manager）的通信以及进行资源的申请、任务的分配和监控等。SparkContext 会向资源管理器注册并申请运行Executor的资源。（2）资源管理器为Executor分配资源，并启动Executor进程，Executor运行情况将随着“心跳”发送到资源管理器上。（3）SparkContext 根据 RDD 的依赖关系构建 DAG 图，DAG 图提交给 DAG 调度器（DAGScheduler）进行解析，将DAG图分解成多个“阶段”（每个阶段都是一个任务集），并且计算出各个阶段之间的依赖关系，然后把一个个“任务集”提交给底层的任务调度器（TaskScheduler）进行处理；Executor 向 SparkContext 申请任务，任务调度器将任务分发给 Executor 运行，同时SparkContext将应用程序代码发放给Executor。（4）任务在Executor上运行，把执行结果反馈给任务调度器，然后反馈给DAG调度器，运行完毕后写入数据并释放所有资源。</p>
<p><img src="/images/2019/picture/Big-data/36.jpeg" alt="架构设计">  </p>
<p>RDD 的设计理念源自 AMP 实验室发表的论文《Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing》</p>
<p>一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可以分成多个分区，每个分区就是一个数据集片段，并且一个 RDD 的不同分区可以被保存到集群中不同的节点上，从而可以在集群中的不同节点上进行并行计算</p>
<p>总体而言，Spark采用RDD以后能够实现高效计算的主要原因如下。</p>
<ul>
<li>（1）高效的容错性</li>
<li>（2）中间结果持久化到内存</li>
<li>（3）存放的数据可以是Java对象，避免了不必要的对象序列化和反序列化开销。</li>
</ul>
<p>4.RDD之间的依赖关系</p>
<p>RDD中不同的操作会使得不同RDD中的分区产生不同的依赖。RDD中的依赖关系分为窄依赖（Narrow Dependency）与宽依赖（Wide Dependency），两种依赖之间的区别如图9-10所示。</p>
<p><img src="/images/2019/picture/Big-data/37.jpeg" alt="架构设计">  </p>
<p>窄依赖表现为一个父RDD的分区对应于一个子RDD的分区，或多个父RDD的分区对应于一个子RDD的分区。</p>
<p>宽依赖则表现为存在一个父 RDD的一个分区对应一个子 RDD的多个分区。</p>
<p>窄依赖典型的操作包括map、filter、union等，宽依赖典型的操作包括groupByKey、sortByKey等。对于连接（Join）操作，可以分为两种情况。</p>
<ul>
<li>（1）对输入进行协同划分，属于窄依赖</li>
<li>（2）对输入做非协同划分，属于宽依赖，</li>
</ul>
<p>对于窄依赖的RDD，可以以流水线的方式计算所有父分区，不会造成网络之间的数据混合。对于宽依赖的RDD，则通常伴随着Shuffle操作，即首先需要计算好所有父分区数据，然后在节点之间进行Shuffle。</p>
<p>5.阶段的划分</p>
<p>Spark通过分析各个RDD的依赖关系生成了DAG，再通过分析各个RDD中的分区之间的依赖关系来决定如何划分阶段，具体划分方法是：在DAG中进行反向解析，遇到宽依赖就断开，遇到窄依赖就把当前的RDD加入到当前的阶段中；将窄依赖尽量划分在同一个阶段中，可以实现流水线计算（具体的阶段划分算法请参见 AMP 实验室发表的论文《Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing》）</p>
<p>由上述论述可知，把一个 DAG 图划分成多个阶段以后，每个阶段都代表了一组关联的、相互之间没有 Shuffle 依赖关系的任务组成的任务集合。每个任务集合会被提交给任务调度器（TaskScheduler）进行处理，由任务调度器将任务分发给Executor运行</p>
<p><img src="/images/2019/picture/Big-data/38.jpeg" alt="架构设计">  </p>
<p>6.RDD运行过程</p>
<p>（1）创建RDD对象。（2）SparkContext负责计算RDD之间的依赖关系，构建DAG。（3）DAGScheduler负责把DAG图分解成多个阶段，每个阶段中包含了多个任务，每个任务会被任务调度器分发给各个工作节点（Worker Node）上的Executor去执行。</p>
<p><img src="/images/2019/picture/Big-data/39.jpeg" alt="架构设计"> </p>
<h2 id="9-4-Spark的部署和应用方式"><a href="#9-4-Spark的部署和应用方式" class="headerlink" title="9.4 Spark的部署和应用方式"></a>9.4 Spark的部署和应用方式</h2><p>本节首先介绍Spark支持的三种典型部署方式，即standalone、Spark on Mesos和Spark on YARN</p>
<h2 id="9-5-Spark编程实践"><a href="#9-5-Spark编程实践" class="headerlink" title="9.5 Spark编程实践"></a>9.5 Spark编程实践</h2><p>表9-2 常用的几个Action API介绍</p>
<p><img src="/images/2019/picture/Big-data/40.jpeg" alt="架构设计"> </p>
<p>表9-3 常用的几个Transformation API介绍</p>
<p><img src="/images/2019/picture/Big-data/41.jpeg" alt="架构设计"> </p>
<p>Spark属于MapReduce计算模型，因此也可以实现MapReduce的计算流程，如实现单词统计，可以首先使用 flatMap()将每一行的文本内容通过空格进行划分为单词；然后使用 map()将单词映射为(K,V)的键值对，其中K为单词，V为1；最后使用reduceByKey()将相同单词的计数进行相加，最终得到该单词总的出现次数。具体实现命令如下：scala &gt; val wordCounts = textFile.flatMap(line =&gt; line.split(“ “)).map(word =&gt; (word, 1)).reduceByKey((a, b) =&gt; a + b)scala &gt; wordCounts.collect() // 输出单词统计结果// Array[(String, Int)]= Array((package,1), (For,2), (Programs,1), (processing.,1), (Because,1), (The,1)…)在上面的代码中，flatMap()、map()和reduceByKey()都是属于“转换”操作，由于Spark采用了惰性机制，这些转换操作只是记录了 RDD 之间的依赖关系，并不会真正计算出结果。最后，运行collect()，它属于“行动”类型的操作，这时才会执行真正的计算，Spark会把计算打散成多个任务分发到不同的机器上并行执行。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/05/prepare-of-time-series/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenxiaolong">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xiaolongc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/05/prepare-of-time-series/" itemprop="url">2.时间序列准备</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-05T22:50:51+08:00">
                2019-09-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/time-series/" itemprop="url" rel="index">
                    <span itemprop="name">time series</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="预测者的工具集"><a href="#预测者的工具集" class="headerlink" title="预测者的工具集"></a>预测者的工具集</h1><p>本章我们会讨论一些在不同预测场景中应用的常用工具。我们将介绍一些基准预测方法，并探讨如何通过数据变换与调整简化预测，如何判断预测是否充分利用了现有信息以及如何计算预测区间。</p>
<h2 id="一些简单的预测方法"><a href="#一些简单的预测方法" class="headerlink" title="一些简单的预测方法"></a>一些简单的预测方法</h2><h3 id="均值法"><a href="#均值法" class="headerlink" title="均值法"></a>均值法</h3><h3 id="Naive-方法"><a href="#Naive-方法" class="headerlink" title="Naïve 方法"></a>Naïve 方法</h3><h3 id="季节性-Naive-方法"><a href="#季节性-Naive-方法" class="headerlink" title="季节性 Naïve 方法"></a>季节性 Naïve 方法</h3><h3 id="漂移法"><a href="#漂移法" class="headerlink" title="漂移法"></a>漂移法</h3><p><strong>例子</strong></p>
<h2 id="变换和调整"><a href="#变换和调整" class="headerlink" title="变换和调整"></a>变换和调整</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/01/rudiments-of-time-series/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenxiaolong">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xiaolongc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/01/rudiments-of-time-series/" itemprop="url">1. 时间序列入门</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-01T16:49:11+08:00">
                2019-09-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/time-series/" itemprop="url" rel="index">
                    <span itemprop="name">time series</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h1><p>开始时，作者讲了一些小典故，非常有意思:</p>
<blockquote>
<p>数千年来，预测一直吸引着人们。古巴比伦的预言家们可以基于蛆在腐烂的绵羊肝脏中的分布预测未来。在公元前300年，想要预知未来的人们会前往希腊的德尔菲祈求神谕，神谕会在被乙醚蒸汽陶醉的情况下给出她的预言。预言家们在康斯坦丁大帝的统治下经历了一段艰难的时期，康斯坦丁大帝在公元357年颁布了一项法令禁止任何人“去咨询占卜者、数学家或预言家，对预言未来的好奇将被永远禁止。”1763年英国颁布了一项相似的禁令：通过预测骗取钱财将被判作犯罪，其刑罚是判处三个月的狱中的苦役。</p>
</blockquote>
<h2 id="什么是可以被预测的"><a href="#什么是可以被预测的" class="headerlink" title="什么是可以被预测的"></a>什么是可以被预测的</h2><p>事件（或数量）的可预测性取决于以下几个因素：</p>
<ul>
<li>我们对它的影响因素的了解程度;</li>
<li>有多少数据是可用的;</li>
<li>预测是否会影响我们试图预测的事物。</li>
</ul>
<h2 id="预测、计划和目标"><a href="#预测、计划和目标" class="headerlink" title="预测、计划和目标"></a>预测、计划和目标</h2><p>该小节讲述了预测、目标以及计划之间的关系。</p>
<p>预测：它是指在考虑到所有可用信息的前提下，包括历史数据和可以影响预测的任何未来事件的知识，尽可能准确地预言。</p>
<p>目标：它是指你想要发生的事情。目标理应与预测和计划联系在一起，但是这并不经常发生。很多时候，设定目标时没有任何如何去实现这些目标的计划，也没有目标是否切合实际的预测。</p>
<p>计划：它是对预测和目标的回应。计划包括制定使得你的预测符合你的目标的适当行动。</p>
<p>而预测又可以分为短期预测、中期预测、长期预测等，具体预测取决于特定的应用场景。</p>
<h2 id="决定预测什么"><a href="#决定预测什么" class="headerlink" title="决定预测什么"></a>决定预测什么</h2><ul>
<li>决定预测什么：<ul>
<li>用于每条产品线或一组产品？</li>
<li>用于每条产品线或一组产品？</li>
<li>每周数据、月度数据或年度数据？</li>
</ul>
</li>
<li>考虑预测的前景时段：<ul>
<li>需要提前1个月，提前6个月还是提前10年预测？</li>
<li>预测需要多频繁？需要经常进行的预测, 最好是使用自动化系统, 而不是需要仔细人工操作。</li>
</ul>
</li>
</ul>
<p>在制定合适的预测方法之前, 预测者大一部分的时间将用于寻找和整理可用数据。</p>
<h2 id="预测数据和方法"><a href="#预测数据和方法" class="headerlink" title="预测数据和方法"></a>预测数据和方法</h2><p>在大程度上，什么数据是可用的决定了适合什么合适的预测方法。</p>
<ul>
<li><p>定性预测：</p>
<ul>
<li>如果没有可用的数据，或者如果可用的数据与预测无关，那么应该使用定性预测方法。</li>
</ul>
</li>
<li><p>在满足以下两个条件的时候可以使用定量预测 ：</p>
<ul>
<li>关于过去的数字化信息是可以用的；</li>
<li>有理由假设过去的一些模式会在未来延续下去。</li>
</ul>
</li>
</ul>
<p>大多数定量预测问题都使用时间序列数据 (按时间间隔定期收集) 或横截面数据 (在一个时间点收集)。在本书中,我们关注预测未来的数据,并且我们主要专注于时间序列领域。</p>
<p>时间序列数据样例包括:</p>
<ul>
<li>IBM每日股票价格</li>
<li>每月降水量</li>
<li>亚马逊季度销售结果</li>
<li>谷歌年度利润</li>
</ul>
<p>最简单的时间序列预测方法只用了预测变量的信息，而不去寻找影响预测变量的因素。因此，这些方法可以推断趋势部分和季节性部分，但是它们会忽略掉所有其他的信息，如营销计划，竞争对手活动，经济状况变动等。</p>
<p>用于预测的时间序列模型包括分解模型，指数平滑模型，ARIMA 模型。这些模型分别在章节 6，7 和 8 中进行了分析探讨。</p>
<h3 id="预测变量与时间序列预测"><a href="#预测变量与时间序列预测" class="headerlink" title="预测变量与时间序列预测"></a>预测变量与时间序列预测</h3><p>以预测夏季每小时用电需求量为例：</p>
<ul>
<li>解释模型</li>
</ul>
<p>ED = f(当前气温，经济实力，人口当日时间，星期几，误差)</p>
<p>这种关系并不确切–总会有不能由预测变量决定的电力需求变化。右侧的“误差”项表示随机波动和没有被包括在模型中的相关变量的影响。我们将它称之为“解释模型”，因为它帮助解释电力需求变化的原因。</p>
<ul>
<li>时间序列模型</li>
</ul>
<center>$$ ED _{t+1} = f(ED _{t}, ED _{t-1}, ED _{t-2}, ED _{t-3}, …, error) $$</center>

<p>t 表示当前的时间， t+1 表示下一个小时，t−1 表示前一个小时，t−2 表示前两个小时，以此类推。此处，对未来的预测是基于变量的过去值，而不是基于可能影响系统的外部变量。同样，右侧的“误差”项允许随机波动和不包含在模型中的相关变量的影响。</p>
<ul>
<li>混合模型：结合了上述两种模型的特点</li>
</ul>
<center>$$ ED _{t+1} = f(ED _{t}, 当前气温，当日时间，星期几，误差) $$</center>

<p>解释模型非常有用,因为它包含了有关其他变量的信息,而不仅仅是要预测的变量的历史值。但是, 预测者可能选择时间序列模型而不是解释性或混合模型的原因有多种：</p>
<ul>
<li>这一系统可能不被理解,即使被理解,也很难衡量被认为应该管理行为的关系。</li>
<li>其次,有必要知道或预测各种预测因子的未来价值, 以便能够预测有意义的变量, 但是这可能太难了。</li>
<li>第三, 可能主要只是关注预测会发生什么,而不知道为什么会发生。</li>
<li>最后,时间序列模型可以提供比解释或混合模型更准确的预测。</li>
</ul>
<p>在预测中使用的模型取决于可用的资源和数据、模型的准确性以及预测模型的使用方式。</p>
<h2 id="案例学习"><a href="#案例学习" class="headerlink" title="案例学习"></a>案例学习</h2><p>该小节，作者讲了4个案例，有以下几个特点：</p>
<ul>
<li>时间序列数据显示出一系列模式，其中一些带有长期趋势，一些带有季节变动，还有一些两者都不具备。</li>
<li>几乎每种药品的销售量数据都包含长期趋势和季节变动模式。很多药品的销量会因药品补贴政策的变化而突然上升或下降，对很多药品的津贴支出也会因出现低价可替代药品而突然发生变化。（因此，我们需要寻找到一种能够对包含长期趋势和季节变动因素的数据进行预测的方法，使得该方法不仅可以对潜在模式下的突然变动进行稳健预测，同时能够处理大样本的时间序列数据。）</li>
<li>一群专家正在预测汽车转售价格。他们认为统计模型的建立会对他们的生计造成威胁，因而在提供信息方面不合作。尽管如此，该公司还是给我们提供了大量的车辆和汽车转售价格的历史数据。</li>
<li>航空乘客人数会受到学校假期、重大体育赛事、广告活动、竞争行为等影响。一般情况下，澳大利亚不同城市的学校假期不会同时出现，体育赛事有时也会从一个城市转移到另一个城市。在历史数据相应期间发生过一场关键飞行员的罢工运动，其间几个月都没有相关航线运行，一条新的低价航线推出后也惨遭失败。在历史数据期间的末尾，航空公司将一些经济舱座位重新改造为商务舱和头等舱座位，然而几个月后，座位安排重新恢复到原来的状态。</li>
</ul>
<h2 id="预测过程的主要步骤"><a href="#预测过程的主要步骤" class="headerlink" title="预测过程的主要步骤"></a>预测过程的主要步骤</h2><p>一个预测过程通常包括五个基本步骤。</p>
<h3 id="定义问题"><a href="#定义问题" class="headerlink" title="定义问题"></a>定义问题</h3><p>通常这是预测中最困难的步骤。要准确定义这个问题，需要了解怎样运用预测方法，谁需要这个预测，以及预测效果如何满足需要这个预测的机构。预测人员需要花费一定时间与所有参与收集数据、维护数据库和使用这个预测对未来进行规划的人沟通。</p>
<h3 id="收集信息"><a href="#收集信息" class="headerlink" title="收集信息"></a>收集信息</h3><p>一般至少需要两种信息收集方式：(a) 统计数据，(b) 收集数据和进行预测方面专家的积累经验。通常情况下，要获得足够多的历史数据以构建良好的统计模型是很困难的。在这种情况下，可以使用 第4节 中的判断预测方法。有时候，陈旧数据会因相应数据发生结构变化而失效，因而我们一般只选择使用较新的数据。然而，一个好的统计模型可以处理系统中的结构变化，因此不要轻易丢弃好的数据。</p>
<h3 id="初步（探索性）分析"><a href="#初步（探索性）分析" class="headerlink" title="初步（探索性）分析"></a>初步（探索性）分析</h3><p>总是以图形开头，观察思考以下几个问题：</p>
<ul>
<li>有一致的模式吗？</li>
<li>有明显的长期趋势吗？</li>
<li>季节性重要吗？</li>
<li>是否有证据表明商业周期存在？</li>
<li>数据中是否包含需要专业知识解释的异常值？</li>
<li>用于分析的变量之间的相关性有多强？</li>
</ul>
<p>目前已经开发了各种工具来帮助进行这种分析。这些将在章节 2 和 章节6中讨论。、</p>
<h3 id="选择及拟合模型"><a href="#选择及拟合模型" class="headerlink" title="选择及拟合模型"></a>选择及拟合模型</h3><p>最佳模型的选择取决于历史数据的可用性、预测变量与各解释变量之间的相关性，以及预测的使用方式。比较两个或三个潜在的模型是很常见的。每个模型本身都基于人为提出的一组假设(显式和隐式)而建立，通常包含一个或多个参数，这些参数必须使用已知的历史数据进行估计。我们将讨论回归模型(章节 5)、指数平滑方法(章节 7)、Box-Jenkins ARIMA模型(章节 8)、动态回归模型(章节 9)、分层预测(章节 10)，以及其他各种方法，包括计数时间序列、神经网络和章节 11中的向量自回归。</p>
<h3 id="使用及评估预测模型"><a href="#使用及评估预测模型" class="headerlink" title="使用及评估预测模型"></a>使用及评估预测模型</h3><p>一旦模型及其参数确定后，该模型就可以用来进行预测。模型的预测效果只有用于预测的数据得到之后才能得到正确的评价。目前已经开发了许多方法来评估预测的准确性。在使用和进行预测时会存在很多组织结构问题。对其中一些问题的简要讨论将在章节 3 中给出。</p>
<h2 id="统计预测观点"><a href="#统计预测观点" class="headerlink" title="统计预测观点"></a>统计预测观点</h2><p>我们试图预测的东西是未知的(或者我们不能预测它)，所以我们可以把它想象成一个随机变量。</p>
<p>例如，下个月的总销售额可能会有一系列的可能值，直到月底我们把实际销售额加起来，我们才知道这个值会是多少。所以在我们知道下个月的销售情况之前，这是一个随机的变量。</p>
<p>因为下个月时间节点比较近，我们通常清楚销售量大概是多少。如果我们预测明年同一个月的销售情况，可能的销售量变动就会较大。在大多数预测情况下，随着事件的临近，预测对象的相关变动较小。换句话说，预测的越早，预测结果越不稳定。</p>
<p>我们可以想象许多可能性，每一个都为我们将要预测的事物带来不同的影响。下图是1980年到2015年澳大利亚的国际游客总数以及2016至2025年的10个可能的预测值。</p>
<p><img src="/images/2019/picture/time-forecast/1-2.png" alt></p>
<blockquote>
<p>用上面10个预测来加权，应该效果不错。</p>
</blockquote>
<p>我们进行预测的过程实际是寻找随机变量可能取值范围内的中间值。通常情况下，预测会伴随着一个预测区间，给出一个随机变量具有较高概率的范围值。例如，95%的预测区间包含一系列的值，这个预测区间包含实际未来值的概率为95%。</p>
<p>我们通常会给出这些预测区间，而不是图 1.2 中显示的单个可能的预测值。下面的图表显示了未来澳大利亚国际游客的80%和95%的预测区间。蓝线是可能的预测值的平均值，我们称之为“点预测”。</p>
<p><img src="/images/2019/picture/time-forecast/1-3.png" alt></p>
<p>使用下标 t 作为时间。例如， $ y _{t} $ 表示时间 t 对应的观察值。假设将观察到的所有信息表示为 T，目标是预测 $ y _{t} $ .此时，我们将 $ y _{t} | T $ 表示为“给定已知 T 情况下的随机变量 $ y _{t} $ ”。这个随机变量取值的概率测度称为 $ y _{t} | T $ 的 “概率分布”。在预测中，我们称之为“预测分布”。</p>
<p>每当我们谈到“预测”时，通常指的是预测分布的平均值，用 $ \hat{y _{t}} $ 来表示 $ y _{t} $ 的预测值，这意味着 $ y _{t} $ 所有可能取值的均值包含了我们所有已知的信息。有时我们将使用 $\hat{y _{t}} $ 来表示预测分布的‘中位数’(或中间值)。</p>
<p>明确指出我们在进行预测时使用的信息是很必要的。例如，我们使用 $ \hat{y _{t}} $ 表示在已知观测值 $ (y _{1},…,y _{t-1}) $ 的情况下 $ y _{t} $ 的预测值。类似地，我们使用 $ \hat{y _{T+h|T}} $ 表示在已知观测值 $ (y _{1},…,y _{T}) $ 的情况下 $ y _{T+h} $ 的预测值（即考虑时间 T 之前所有观测值的h步预测）.</p>
<h2 id="拓展阅读"><a href="#拓展阅读" class="headerlink" title="拓展阅读"></a>拓展阅读</h2><ul>
<li>Armstrong (2001) 涵盖了整个预测领域的内容，每个章节都由不同的专家撰写。文章部分观点非常武断(我们并不同意其中的观点)，但在处理预测问题上有很多优秀的一般性建议。</li>
<li>Ord, Fildes, and Kourentzes (2017) 是一本预测教材，涵盖了与本书相同的部分，但重点不同，它不关注任何特定的软件环境。这是由三位有着几十年经验的权威预测专家撰写的。</li>
</ul>
<h1 id="时间序列图形"><a href="#时间序列图形" class="headerlink" title="时间序列图形"></a>时间序列图形</h1><p>对于任何数据分析工作而言，其首要任务是数据可视化。图示化数据可以清晰地展现数据的特征，包括数据的形态、异常值、随时间变化情况以及变量间的相互关系。我们在预测时应尽可能地将图中显示的特征纳入考虑。正如数据类型决定使用什么预测方法一样，数据类型也决定了使用什么图形来展示数据。</p>
<p>在画图之前，首先我们应该在R中设置我们的时间序列数据。</p>
<h2 id="ts-对象"><a href="#ts-对象" class="headerlink" title="ts 对象"></a>ts 对象</h2><p>R语言中的一种记录时序的对象。</p>
<pre><code>y &lt;- ts(c(123,39,78,52,110), start=2012)
</code></pre><h2 id="时间图"><a href="#时间图" class="headerlink" title="时间图"></a>时间图</h2><p>对于时间序列数据而言，我们从最简单的时间图开始。时间图是用将观测值与观测时间点作图，散点之间用直线连接。例如图2.1表示在澳大利亚两个最大的城市之间，Ansett航空公司的每周客流量。</p>
<p><img src="/images/2019/picture/time-forecast/2-1.png" alt></p>
<p>该时间图直观地展现出数据具有的一些特征：</p>
<ul>
<li>由于1989年当地的工业纠纷，当年的客流量为0.</li>
<li>在1992年中，由于一部分经济舱被商务舱取代，导致客流量大幅减少。</li>
<li>1991年下半年客流量大幅上升。</li>
<li>由于假日效应，在每年年初，客流量都会有一定幅度的下降。</li>
<li>这是序列存在长期波动，在1987年向上波动，在1988年向下波动，而在1990年和1991年又再次向上波动。</li>
<li>在某些时期存在缺失值。</li>
</ul>
<p><img src="/images/2019/picture/time-forecast/2-2.png" alt></p>
<ul>
<li>显然，图示的时间序列具有明显增长的趋势。</li>
<li>同时，在上升趋势中伴随着明显的季节性。</li>
<li>在每年年底，由于政府补贴计划，使得降糖药品更便宜，所以人们倾向于在年底囤积药物，从而导致年初的销售额大幅下降。</li>
<li>因此，当我们对降糖药物的销量进行预测时，需同时考虑其趋势和季节性因素。</li>
</ul>
<h2 id="时间序列形态"><a href="#时间序列形态" class="headerlink" title="时间序列形态"></a>时间序列形态</h2><p>我们通常使用例如“趋势”、“季节性”等词语描述时间序列。在深入研究时间序列形态时，应该更精确的定义这些词语。</p>
<h3 id="趋势"><a href="#趋势" class="headerlink" title="趋势"></a>趋势</h3><p>当一个时间序列数据长期增长或者长期下降时，表示该序列有 <code>趋势</code> 。在某些场合，趋势代表着“转换方向”。例如从增长的趋势转换为下降趋势。在图 2.2 中，明显存在一个增长的趋势。</p>
<h3 id="季节性"><a href="#季节性" class="headerlink" title="季节性"></a>季节性</h3><p>当时间序列中的数据受到季节性因素（例如一年的时间或者一周的时间）的影响时，表示该序列具有 <code>季节性</code> 。季节性总是一个已知并且固定的频率。由于抗糖尿病药物的成本在年底时会有变化，导致上述抗糖尿药物的月销售额存在季节性。</p>
<h3 id="周期性"><a href="#周期性" class="headerlink" title="周期性"></a>周期性</h3><p>当时间序列数据存在不固定频率的上升和下降时，表示该序列有 <code>周期性</code> 。这些波动经常由经济活动引起，并且与“商业周期”有关。周期波动通常至少持续两年。</p>
<blockquote>
<p>许多初学者都不能很好的区分季节性和周期，然而这两个概念是完全不同的。当数据的波动是无规律时，表示序列存在周期性；如果波动的频率不变并且与固定长度的时间段有关，表示序列存在季节性。一般而言，周期的长度较长，并且周期的波动幅度也更大。</p>
</blockquote>
<p>许多时间序列同时包含趋势、季节性以及周期性。当我们选择预测方法时，首先应该分析时间序列数据所具备的特征，然后再选择合适的预测方法抓取特征。</p>
<p>以下四个示例分别是上述三个特征的不同组合。</p>
<p><img src="/images/2019/picture/time-forecast/2-3.png" alt></p>
<ul>
<li>美国新建房屋销售额（左上）表现出强烈的年度季节性，以及周期为6~10年的周期性。但是数据并没有表现出明显的趋势。</li>
<li>美国国债价格（右上）表示1981年美国国债在芝加哥市场连续100个交易日的价格。可以看出，该序列并没有季节性，但是有明显下降的趋势。假如我们拥有该序列更多的观测数据，我们可以看到这个下降的趋势是一个长期循环的一部分。但是现在我们只有连续100天的数据，它表现出下降的趋势。</li>
<li>澳大利亚月度电力产值数据（左下）明显表现出向上增长的趋势，以及强季节性。但是并不存在周期性。</li>
<li>Google收盘股价格（右下）的价格波动没有趋势，季节性和周期性。随机波动没有良好的形态特性，不能很好地预测。</li>
</ul>
<h2 id="季节图"><a href="#季节图" class="headerlink" title="季节图"></a>季节图</h2><p>季节图和时间序列图很相似，不同之处是季节图是针对观察数据的“季节性”绘制的。下面的例子是降糖药物的销售情况。</p>
<p><img src="/images/2019/picture/time-forecast/2-4.png" alt></p>
<p>在早些年，数据形态基本相同，但是近些年数据存在相互堆叠的情况。季节图可以很清晰的显示季节形态，这对识别数据形态是否发生变化非常有效。</p>
<p>在本例中，在每年一月份降糖药物的销量都会大幅下降。实际上，患者会在12月下旬大量购买降糖药物，但是这部分销量会在一两周后才向政府登记。从上图还可以看出，2008年3月销量大幅下降（其他年份2月份至3月份的销量增加）。2008年6月份销量较少可能是由于销量数据收集不完整导致。</p>
<p>季节图中可以将直角坐标转换为极坐标。</p>
<p><img src="/images/2019/picture/time-forecast/2-5.png" alt></p>
<h2 id="子系列季节图"><a href="#子系列季节图" class="headerlink" title="子系列季节图"></a>子系列季节图</h2><p><img src="/images/2019/picture/time-forecast/2-6.png" alt></p>
<p>图中的水平线表示每月的平均销量。子系列季节图可以清晰的描绘出数据的潜在季节性形态，并且显示了季节性随时间的变化情况。这类图可以很好地查看各时期内数据的变化情况。在本例中，子系列季节图并没有明显地体现数据特性，但是这是观察季节性变化最有用的方式。</p>
<h2 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h2><p>在此之前，我们所讨论的内容都是单个时间序列的可视化。此外，多个时间序列的可视化也是非常有用的。 图 2.7 分别展示了两个时间序列：2014年澳大利亚维多利亚州每半小时的用电量（以千兆瓦为单位）和温度（以摄氏度为单位）</p>
<p><img src="/images/2019/picture/time-forecast/2-7.png" alt></p>
<p><img src="/images/2019/picture/time-forecast/2-8.png" alt></p>
<p>这个散点图可以很好的帮助我们理解变量之间的相互关系。从图中我们可以看出，当温度很高时，人们会大量的使用空调进行降温，进而导致用电量随之增加；当温度很低时，人们会使用空调取暖，也会使得用电量一定程度上增加。</p>
<h3 id="相关性"><a href="#相关性" class="headerlink" title="相关性"></a>相关性</h3><p>我们经常会用 相关系数 衡量两个两个变量之间的相关强度。假如已知两个变量 x 和 y ，那么它们之间的相关系数为：</p>
<center> $$ r = \frac{\sum (x _{t} - \bar{x})(y _{t} - \bar{y}))}{\sqrt{\sum (x _{t}- \bar{x}) ^{2}}\sqrt{\sum (y _{t}-\bar{y}) ^{2}}} $$ </center>

<p>r 的值始终在-1到1之间。当两个变量完全负相关时，r 值为-1；当两个变量完全正相关时，r 为1.图 2.9 分别展示了不同相关强度的例子。</p>
<p><img src="/images/2019/picture/time-forecast/2-9.png" alt></p>
<p>需要注意的是，相关系数仅仅衡量了变量之间的线性关系，并且有时会导致错误的结果。例如，在图 2.10中，所有例子的相关系数均为0.82，但是它们有着完全不同的形态。 这表明，在分析变量之间关系时，不仅要看相关系数值，而且要关注生成的图形。</p>
<p><img src="/images/2019/picture/time-forecast/2-10.png" alt></p>
<p>在图 2.8中，用电量和温度之间的相关系数仅为0.2798，但并不代表用电量和温度之间存在很强的非线性关系。</p>
<h3 id="散点图矩阵"><a href="#散点图矩阵" class="headerlink" title="散点图矩阵"></a>散点图矩阵</h3><p>当所分析的数据有多个变量时，将每个变量与其他变量进行比较也很有意义。如图2.11所示，表示澳大利亚新南威尔士五个地区的季度游客人数。</p>
<p><img src="/images/2019/picture/time-forecast/2-11.png" alt></p>
<p>如图 2.12所示，我们可以绘制出它们的散点图矩阵。</p>
<p><img src="/images/2019/picture/time-forecast/2-12.png" alt></p>
<p>我们可以通过散点图矩阵快速查看所有变量之间的相关关系。在本例中，由图中第二列数据可知，新南威尔士州北部海岸游客与新南威尔士南部海岸游客之间存在强烈的正关系，而新南威尔士州北部海岸的游客与新南威尔士内陆游客之间几乎没有相关关系。同时，我们可以通过散点图矩阵检测到异常值。由于2000年悉尼奥运会，新南威尔士大都会地区存在异常大的客流量。</p>
<h2 id="滞后图"><a href="#滞后图" class="headerlink" title="滞后图"></a>滞后图</h2><p>图 2.13是澳大利亚每季度啤酒产量的散点图，横轴表示时间序列的滞后阶数。各图分别显示了不同 k 值下 $ y _{t} $ 和 $ y _{t-k} $ 的散点图。</p>
<p><img src="/images/2019/picture/time-forecast/2-13.png" alt></p>
<p>2-13 澳大利亚每季度啤酒产量不同滞后阶数散点图</p>
<p>图中不同颜色代表不同季节，每条线都按时间顺序连接。从图中可以看出，滞后四阶和滞后八阶有正相关关系，说明数据具有很强的季节性。二阶滞后图和六阶滞后图显示，第四季度的峰值对应第二季度的最低点。</p>
<h2 id="自相关"><a href="#自相关" class="headerlink" title="自相关"></a>自相关</h2><p>正如相关系数可以衡量两个变量之间的线性相关关系一样，自相关系数可以测量时间序列 滞后值 之间的线性关系。</p>
<p>以下几个不同的自相关系数，对应于滞后图中的不同情况。例如， $ r _{1} $ 衡量 $ y _{t} $ 和 $ y _{t-1} $ 之间的关系， $ r _{2} $ 衡量 $ y _{t} $ 和 $ y _{t-2} $ 之间的关系.</p>
<p>其中， $ r _{k} $ 的定义如下：</p>
<center> $$ r <em>{k}=\frac{\sum</em>{t=k+1}^{T}(y _{t}-\bar{y})(y <em>{t-k}-\bar{y})}{\sum</em>{t=1}^{T}(y _{t}-\bar{y})^{2}} $$ </center>

<p>其中，T 是时间序列的长度。</p>
<p>澳大利亚啤酒产量数据的前九个自相关系数如下表所示。（略）</p>
<p>各值分别对应于图 2.13 中的九个散点图。通过绘制自相关系数图可以描绘 自相关函数 或者是ACF。因此也被称为相关图。</p>
<p><img src="/images/2019/picture/time-forecast/2-14.png" alt></p>
<p>在该图中：</p>
<ul>
<li>$ r _{4} $ 值最大。这是由于数据的季节性形态：顶峰往往出现在第四季度，谷底往往出现在第二季度。</li>
<li>$ r _{2} $ 值最小。这是由于谷底往往在高峰之后的两个季度出现。</li>
<li>蓝色虚线之内的区域自相关性可近似看做0。这将会在下节详细阐述。</li>
</ul>
<h3 id="ACF-图中的趋势性和季节性"><a href="#ACF-图中的趋势性和季节性" class="headerlink" title="ACF 图中的趋势性和季节性"></a>ACF 图中的趋势性和季节性</h3><p>当数据具有趋势性时，短期滞后的自相关值较大，因为观测点附近的值波动不会很大。时间序列的ACF一般是正值，随着滞后阶数的增加而缓慢下降。</p>
<p>当数据具有季节性时，自相关值在滞后阶数与季节周期相同时（或者在季节周期的倍数）较大。</p>
<p>当数据同时具有趋势和季节性时，我们会观察到组合效应。如图 2.15 是澳大利亚用电量，该序列同时具有趋势和季节性。它的ACF值如图 2.16 所示。</p>
<p><img src="/images/2019/picture/time-forecast/2-15.png" alt></p>
<p><img src="/images/2019/picture/time-forecast/2-16.png" alt></p>
<p>自相关系数值随着滞后阶数增加而缓慢降低，是因为原时间序列中具有趋势变化，而图中的“圆齿状”形状是来源于原时间序列中的季节性变化。</p>
<h2 id="白噪声"><a href="#白噪声" class="headerlink" title="白噪声"></a>白噪声</h2><p>“白噪声”是一个对所有时间其自相关系数为零的随机过程。 图 2.17是一个白噪声的例子。</p>
<p><img src="/images/2019/picture/time-forecast/2-17.png" alt></p>
<p>白噪声函数的自相关函数如下图所示：</p>
<p><img src="/images/2019/picture/time-forecast/2-18.png" alt></p>
<p>对于白噪声而言，我们期望它的自相关值接近0。但是由于随机扰动的存在，自相关值并不会精确地等于0。对于一个长度为 T 的白噪声序列而言，我们期望在0.95的置信度下，它的自相关值处于 $ \pm 2/\sqrt{T} $ 之间。我们可以很容易的画出ACF的边界值（图中蓝色虚线）。如果一个序列中有较多的自相关值处于边界之外，那么该序列很可能不是白噪声序列。</p>
<p>在上例中，序列长度 T = 50，边界为 $ \pm 2/\sqrt{50} = \pm 0.28 $ 。所有的自相关值均落在边界之内，证明序列是白噪声.</p>
<h2 id="拓展阅读-1"><a href="#拓展阅读-1" class="headerlink" title="拓展阅读"></a>拓展阅读</h2><ul>
<li>Cleveland (1993) 是关于数据分析可视化原理的经典著作。虽然已有20多年历史，但它的思想永不过时。</li>
<li>Unwin (2015) 是一本关于使用R进行图形数据分析的前沿著作。它并没有着重介绍如何绘制时间序列图形，更多的是关于使用图形进行数据分析。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/01/fbprophet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenxiaolong">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xiaolongc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/01/fbprophet/" itemprop="url">5. fbprophet原理及实战</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-01T16:13:28+08:00">
                2019-09-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">machine learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="fbprophet简介"><a href="#fbprophet简介" class="headerlink" title="fbprophet简介"></a>fbprophet简介</h1>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/01/xgboost/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenxiaolong">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xiaolongc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/01/xgboost/" itemprop="url">4. xgboost原理及实战</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-01T16:11:58+08:00">
                2019-09-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">machine learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="XGBoost-与-Boosted-Tree（GBDT）"><a href="#XGBoost-与-Boosted-Tree（GBDT）" class="headerlink" title="XGBoost 与 Boosted Tree（GBDT）"></a>XGBoost 与 Boosted Tree（GBDT）</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>作为一个非常有效的机器学习方法，Boosted Tree是数据挖掘和机器学习中最常用的算法之一。因为它效果好，对于输入要求不敏感，往往是从统计学家到数据科学家必备的工具之一，它同时也是kaggle比赛冠军选手最常用的工具。最后，因为它的效果好，计算复杂度不高，也在工业界中有大量的应用。</p>
<h2 id="Boosted-Tree-同义词"><a href="#Boosted-Tree-同义词" class="headerlink" title="Boosted Tree 同义词"></a>Boosted Tree 同义词</h2><p>Boosted Tree有各种马甲，比如GBDT, GBRT (gradient boosted regression tree)，MART，LambdaMART也是一种boosted tree的变种。网上有很多介绍Boosted tree的资料，不过大部分都是基于Friedman的最早一篇文章Greedy Function Approximation: A Gradient Boosting Machine的翻译。</p>
<h2 id="有监督学习的算法的逻辑组成"><a href="#有监督学习的算法的逻辑组成" class="headerlink" title="有监督学习的算法的逻辑组成"></a>有监督学习的算法的逻辑组成</h2><p>有监督学习里面有几个逻辑上的重要组成部件，初略地分可以分为：模型，参数 和目标函数。</p>
<p>(1) 模型和参数</p>
<p>模型指给定输入xi如何去预测 输出 yi。我们比较常见的模型如线性模型（包括线性回归和logistic regression）采用了线性叠加的方式进行预测 $ \hat{y_{i}}=\sum_{j}w_{j}x_{ij} $ . 其实，这里的预测y可以有不同的解释，比如我们可以用它来作为回归目标的输出，或者进行sigmoid 变换得到概率，或者作为排序的指标等。而一个线性模型根据y的解释不同（以及设计对应的目标函数）用到回归，分类或排序等场景。</p>
<p>参数指我们需要学习的东西，在线性模型中，参数指我们的线性系数w。</p>
<p>(2) 目标函数：损失+正则</p>
<p>模型和参数本身指定了给定输入我们如何做预测，但是没有告诉我们如何去寻找一个比较好的参数，这个时候就需要目标函数登场了。一般的目标函数包含下面两项：</p>
<p><img src="/images/2019/picture/xgboost/1.png" alt="误差函数"></p>
<p>常见的误差函数有 $ L=\sum_{i}^{m}l(y_{i},\hat{y_{i}}) $ , 比如平方误差 $ l(y_{i},\hat{y_{i}})=(y_{i},\hat{y_{i}})^{2} $, logistic 误差 $ l(y_{i},\hat{y_{i}})=y_{i}In(1+e^{-\hat{y_{i}}})+(1-y_{i})In(1+e^{\hat{y_{i}}}) $ 。</p>
<p>而对于线性模型常见的正则化项有L2正则和L1正则。这样目标函数的设计来自于统计学习里面的一个重要概念叫做Bias-variance tradeoff。比较感性的理解，Bias可以理解为假设我们有无限多数据的时候，可以训练出最好的模型所拿到的误差。而Variance是因为我们只有有限数据，其中随机性带来的误差。目标中误差函数鼓励我们的模型尽量去拟合训练数据，这样相对来说最后的模型会有比较少的 bias。而正则化项则鼓励更加简单的模型。因为当模型简单之后，有限数据拟合出来结果的随机性比较小，不容易过拟合，使得最后模型的预测更加稳定。</p>
<p>(3) 优化算法</p>
<p>讲了这么多有监督学习的基本概念，为什么要讲这些呢？ 是因为这几部分包含了机器学习的主要成分，也是机器学习工具设计中划分模块比较有效的办法。其实这几部分之外，还有一个优化算法，就是给定目标函数之后怎么学的问题。<font color="orange"> 之所以我没有讲优化算法，是因为这是大家往往比较熟悉的“机器学习的部分”。而有时候我们往往只知道“优化算法”，而没有仔细考虑目标函数的设计的问题，比较常见的例子如决策树的学习，大家知道的算法是每一步去优化gini entropy，然后剪枝，但是没有考虑到后面的目标是什么。</font></p>
<h2 id="Boosted-Tree"><a href="#Boosted-Tree" class="headerlink" title="Boosted Tree"></a>Boosted Tree</h2><p>(1) 基学习器：分类和回归树（CART）</p>
<p>话题回到boosted tree，我们也是从这几个方面开始讲，首先讲模型。Boosted tree 最基本的组成部分叫做回归树(regression tree)，也叫做CART。</p>
<p><img src="/images/2019/picture/xgboost/2.png" alt></p>
<p>上面就是一个CART的例子。CART会把输入根据输入的属性分配到各个叶子节点，而每个叶子节点上面都会对应一个实数分数。上面的例子是一个预测一个人是否会喜欢电脑游戏的 CART，你可以把叶子的分数理解为有多可能这个人喜欢电脑游戏。有人可能会问它和decision tree的关系，其实我们可以简单地把它理解为decision tree的一个扩展。从简单的类标到分数之后，我们可以做很多事情，如概率预测，排序。</p>
<p>(2) Tree Ensemble</p>
<p>一个CART往往过于简单无法有效地预测，因此一个更加强力的模型叫做tree ensemble。</p>
<p><img src="/images/2019/picture/xgboost/3.png" alt></p>
<p>在上面的例子中，我们用两棵树来进行预测。我们对于每个样本的预测结果就是每棵树预测分数的和。到这里，我们的模型就介绍完毕了。现在问题来了，我们常见的随机森林和boosted tree和tree ensemble有什么关系呢？如果你仔细的思考，你会发现RF和boosted tree的模型都是tree ensemble，只是构造（学习）模型参数的方法不同。<font color="orange"> 第二个问题：在这个模型中的“参数”是什么。在tree ensemble中，参数对应了树的结构，以及每个叶子节点上面的预测分数。</font></p>
<p>最后一个问题当然是如何学习这些参数。在这一部分，答案可能千奇百怪，但是最标准的答案始终是一个：<font color="orange"> 定义合理的目标函数，然后去尝试优化这个目标函数。在这里我要多说一句，因为决策树学习往往充满了heuristic。 如先优化吉尼系数，然后再剪枝啦，限制最大深度，等等。其实这些heuristic的背后往往隐含了一个目标函数，而理解目标函数本身也有利于我们设计学习算法，这个会在后面具体展开。</font></p>
<p>对于tree ensemble，我们可以比较严格的把我们的模型写成是：</p>
<center>$$ \hat{y_{i}}=\sum_{k=1}^{K}f_{k}(x_{i}),f_{k}\epsilon F $$</center>

<p>其中，每个 f 是一个函数空间里面的函数，而F对应了所有regression tree的集合。我们设计的目标函数也需要遵循前面的主要原则，包含两部分:</p>
<p><img src="/images/2019/picture/xgboost/4.png" alt></p>
<p>(3) 模型学习：additive training</p>
<p>其中第一部分是训练误差，也就是大家相对比较熟悉的如平方误差, logistic loss等。而第二部分是每棵树的复杂度的和。这个在后面会继续讲到。因为现在我们的参数可以认为是在一个函数空间里面，我们不能采用传统的如SGD之类的算法来学习我们的模型，因此我们会采用一种叫做additive training的方式（另外，在我个人的理解里面[7]，boosting就是指additive training的意思）。每一次保留原来的模型不变，加入一个新的函数f到我们的模型中。</p>
<p><img src="/images/2019/picture/xgboost/5.png" alt></p>
<p>现在还剩下一个问题，我们如何选择每一轮加入什么ff呢？答案是非常直接的，选取一个ff来使得我们的目标函数尽量最大地降低[8]。</p>
<p><img src="/images/2019/picture/xgboost/6.png" alt></p>
<p>这个公式可能有些过于抽象，我们可以考虑当损失函数是平方误差的情况。这个时候我们的目标可以被写成下面这样的二次函数：</p>
<p><img src="/images/2019/picture/xgboost/7.png" alt></p>
<p>更加一般的，对于不是平方误差的情况，我们会采用如下的泰勒展开近似来定义一个近似的目标函数，方便我们进行这一步的计算。</p>
<p><img src="/images/2019/picture/xgboost/8.png" alt></p>
<p>举个例子，当时平方损失时：</p>
<p><img src="/images/2019/picture/xgboost/10.png" alt></p>
<p>当我们把常数项移除之后，我们会发现如下一个比较统一的目标函数。这一个目标函数有一个非常明显的特点，它只依赖于每个数据点的在误差函数上的一阶导数和二阶导数[10]。有人可能会问，这个材料似乎比我们之前学过的决策树学习难懂。为什么要花这么多力气来做推导呢？</p>
<p><img src="/images/2019/picture/xgboost/9.png" alt></p>
<p>因为这样做使得我们可以很清楚地理解整个目标是什么，并且一步一步推导出如何进行树的学习。这一个抽象的形式对于实现机器学习工具也是非常有帮助的。传统的GBDT可能大家可以理解如优化平法残差，但是这样一个形式包含可所有可以求导的目标函数。也就是说有了这个形式，我们写出来的代码可以用来求解包括回归，分类和排序的各种问题，正式的推导可以使得机器学习的工具更加一般。</p>
<p>(4) 树的复杂度</p>
<p>到目前为止我们讨论了目标函数中训练误差的部分。接下来我们讨论如何定义树的复杂度。我们先对于f的定义做一下细化，把树拆分成结构部分q和叶子权重部分w。下图是一个具体的例子。结构函数q把输入映射到叶子的索引号上面去，而w给定了每个索引号对应的叶子分数是什么。</p>
<p><img src="/images/2019/picture/xgboost/11.png" alt></p>
<p>当我们给定了如上定义之后，我们可以定义一棵树的复杂度如下。这个复杂度包含了一棵树里面节点的个数，以及每个树叶子节点上面输出分数的L2模平方。当然这不是唯一的一种定义方式，不过这一定义方式学习出的树效果一般都比较不错。下图还给出了复杂度计算的一个例子。</p>
<p><img src="/images/2019/picture/xgboost/12.png" alt></p>
<p>(5) 关键步骤</p>
<p>接下来是最关键的一步1111，在这种新的定义下，我们可以把目标函数进行如下改写，其中I被定义为每个叶子上面样本集合 $ I_{j}={i|q(x_{i})=j} $ </p>
<p><img src="/images/2019/picture/xgboost/13.png" alt></p>
<p>其中，上式第二步到第三步的转换是个关键，即将 n 个样本折算到 T 个叶子节点上，每个叶子节点所对应的数值是一致的，因此通过叶子节点所对应的样本个数来改写损失函数。</p>
<p>这一个目标包含了T个相互独立的单变量二次函数。我们可以定义:</p>
<center>$$ G_{j}=\sum_{i\epsilon I_{j}}g_{i}, H_{j}=\sum_{i\epsilon I_{j}}h_{i} $$</center>

<p>那么这个目标函数可以进一步改写成如下的形式，假设我们已经知道树的结构q，我们可以通过这个目标函数来求解出最好的w，以及最好的w对应的目标函数最大的增益:</p>
<p><img src="/images/2019/picture/xgboost/14.png" alt></p>
<p>这两个的结果对应如下，左边是最好的w，右边是这个w对应的目标函数的值。到这里大家可能会觉得这个推导略复杂。其实这里只涉及到了如何求一个一维二次函数的最小值的问题。如果觉得没有理解不妨再仔细琢磨一下.</p>
<p><img src="/images/2019/picture/xgboost/15.png" alt></p>
<p>(6) 打分函数计算举例</p>
<p>Obj代表了当我们指定一个树的结构的时候，我们在目标上面最多减少多少。我们可以把它叫做结构分数(structure score)。你可以认为这个就是类似吉尼系数一样更加一般的对于树结构进行打分的函数。下面是一个具体的打分函数计算的例子:</p>
<p><img src="/images/2019/picture/xgboost/16.png" alt></p>
<p>(7) 枚举所有不同树结构的贪心法</p>
<p>所以我们的算法也很简单，我们不断地枚举不同树的结构，利用这个打分函数来寻找出一个最优结构的树，加入到我们的模型中，再重复这样的操作。不过枚举所有树结构这个操作不太可行，所以常用的方法是贪心法，每一次尝试去对已有的叶子加入一个分割。对于一个具体的分割方案，我们可以获得的增益可以由如下公式计算：</p>
<p><img src="/images/2019/picture/xgboost/17.png" alt></p>
<font color="orange">Obj 越小越好，表明分割后的树结构对应的 Obj1  应该比分割前的 Obj2 要小，因此，定义 Gain = (Obj1-Obj2) , 这个增益越大越好。</font>

<p>对于每次扩展，我们还是要枚举所有可能的分割方案，如何高效地枚举所有的分割呢？我假设我们要枚举所有 x小于a 这样的条件，对于某个特定的分割a我们要计算a左边和右边的导数和。</p>
<p><img src="/images/2019/picture/xgboost/18.png" alt></p>
<p>我们可以发现对于所有的a，我们只要做一遍从左到右的扫描就可以枚举出所有分割的梯度和GL和GR。然后用上面的公式计算每个分割方案的分数就可以了。</p>
<p>观察这个目标函数，大家会发现第二个值得注意的事情就是引入分割不一定会使得情况变好，因为我们有一个引入新叶子的惩罚项。优化这个目标对应了树的剪枝， 当引入的分割带来的增益小于一个阀值的时候，我们可以剪掉这个分割。大家可以发现，当我们正式地推导目标的时候，像计算分数和剪枝这样的策略都会自然地出现，而不再是一种因为heuristic而进行的操作了。</p>
<p>讲到这里文章进入了尾声，虽然有些长，希望对大家有所帮助，这篇文章介绍了如何通过目标函数优化的方法比较严格地推导出boosted tree的学习。因为有这样一般的推导，得到的算法可以直接应用到回归，分类排序等各个应用场景中去。</p>
<h1 id="xgboost-的工程优化"><a href="#xgboost-的工程优化" class="headerlink" title="xgboost 的工程优化"></a>xgboost 的工程优化</h1><h1 id="xgboost-和-GBDT之间的区别"><a href="#xgboost-和-GBDT之间的区别" class="headerlink" title="xgboost 和 GBDT之间的区别"></a>xgboost 和 GBDT之间的区别</h1><h1 id="xgboost-的其他特性"><a href="#xgboost-的其他特性" class="headerlink" title="xgboost 的其他特性"></a>xgboost 的其他特性</h1><h2 id="缺失值的处理"><a href="#缺失值的处理" class="headerlink" title="缺失值的处理"></a>缺失值的处理</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/07/GBDT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenxiaolong">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xiaolongc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/07/GBDT/" itemprop="url">3. GBDT</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-07T22:38:27+08:00">
                2019-08-07
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">machine learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="提升树模型"><a href="#提升树模型" class="headerlink" title="提升树模型"></a>提升树模型</h1><p>提升方法实际采用加法模型(即基函数的线性组合)与前向分布算法。以决策树为基函数的提升方法称为提升树(boosting tree)。<font color="orange">提升树模型和梯度提升树是两种不同的模型，梯度提升是在提升树模型上进一步优化。提升树对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树；而梯度提升树对分类问题、回归问题都使用的是CART回归树。具体情况，还需要查看其对应的实现方法。TODO：sklearn里面的GBDT实现方式。</font> 提升树模型可以表示为决策树的加法模型：</p>
<center>$$ f_{M}(x)=\sum_{m=1}^{M}T(x;\Theta_{m}) $$</center><br>其中 $ T(x;\Theta_{m}) $ 表示决策树， $ \Theta_{m} $ 为决策树的参数， M 为树的个数。<br><br># 提升树算法<br><br>提升树算法采用前向分布算法，首先确定初始提升树 $ f_{0}=0 $ ,第m步的模型是： $ f_{m}=f_{m-1}(x)+T(x; \Theta_{m}) $ 。<br><br>其中， $ f_{m-1}(x) $ 为当前模型，通过经验风险极小化确定下一颗决策树参数 $ \Theta_{m} $ ：<br><center>$$ \Theta_{m}^{*}=argmin_{\Theta_{m}}\sum_{i=1}^{N}L(y_{i},f_{m-1}(x_{i})+T(x_{i};\Theta_{m})) $$</center>

<p>树的线性组合可以很好的拟合训练数据，即使数据中的输入与输出关系复杂也是，所以提升树一般是高功能的学习算法。</p>
<font color="orange">下面讨论针对不同问题的提升树学习算法，主要区别在于损失函数的不同。包括用平方误差损失的回归问题，用指数损失函数的分类问题，以及用一般损失函数的决策问题。</font>

<h2 id="二分类问题"><a href="#二分类问题" class="headerlink" title="二分类问题"></a>二分类问题</h2><p>对于二分类问题，提升树算法只需将 AdaBoost 算法中的基本分类器限定为二类分类树即可，可以说这时的提升树算法是 AdaBoost 算法的特殊情况。</p>
<h2 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h2><p>已知一个训练数据集 $ T = ((x_{1},y_{1}),(x_{2},y_{2}),…,(x_{N},y_{N})),x_{i}\epsilon \chi \subseteq \mathbb{R}^{n} $ , $ \chi $ 为输入空间，$ y_{i}\epsilon y \subseteq \mathbb{R} $, y 为输出空间。如果将输入空间 $ \chi $ 划分为 $ \jmath  $ 个互不相交的区域 $ R_{1},R_{2},…,R_{J} $ ，并且在每个区域上确定输出常量 $ c_{j} $ , 那么树可表示为:</p>
<center>$$ T(x;\Theta)=\sum_{j=1}^{J}c_{j}I(x\epsilon R_{j}) $$</center>

<p>其中，参数 $ \Theta = ((R_{1},c_{1}),(R_{2},c_{2}),…,(R_{J},c_{J})) $ 表示树的区域划分和各区域上的常数，J 是回归树的复杂度，即叶节点个数。</p>
<p>回归问题提升树的前向分布算法为：</p>
<center>$$ f_{0}(x)=0 $$</center><br><center>$$ f_{m}(x)=f_{m-1}+T(x;\Theta_{m}),m=1,2,…,M $$</center><br><center>$$ f_{M}(x)=\sum_{m=1}^{M}T(x;\Theta_{m}) $$</center>

<p>在前向分布算法的第m步，给定当前模型 $ f_{m-1}(x) $, 需求解</p>
<center>$$ \hat{\Theta_{m}}=arg\underset{\Theta_{m}}{min}\sum_{i=1}^{N}L(y_{i},f_{m-1}(x_{i})+T(x_{i};\Theta_{m})) $$</center>

<p>得到 $ \hat{\Theta_{m}} $，即第m颗树的参数.</p>
<p>当采用平方误差损失函数时,</p>
<center>$$ L(y,f(x))=(y-f(x))^{2} $$</center>

<p>其损失函数为:</p>
<center>$$ L(y,f_{m-1}(x)+T(x;\Theta_{m}))=[y-f_{m-1}(x)-T(x;\Theta_{m})]^{2}=[r-T(x;\Theta_{m})]^{2} $$</center>

<p>这里的 $ r=y-f_{m-1}(x) $, 是当前模型拟合数据的残差。所以，对于回归模型的提升树而言，只需简单的拟合当前模型的残差。</p>
<h2 id="回归问题的提升树算法"><a href="#回归问题的提升树算法" class="headerlink" title="回归问题的提升树算法"></a>回归问题的提升树算法</h2><p>输入：训练数据集 $ T = ((x_{1},y_{1}),(x_{2},y_{2}),…,(x_{N},y_{N})),x_{i}\epsilon \chi \subseteq \mathbb{R}^{n} $.</p>
<p>输出：提升树 $ f_{M}(x) $.</p>
<ul>
<li>(1) 初始化 $ f_{0}(x)=0 $</li>
<li>(2) 对 m=1,2,…,M<br>– (a)按上式计算残差 $  r_{mi}=y_{i}-f_{m-1}(x_{i}), i=1,2,…,N $<br>– (b)拟合残差 $ r_{mi} $ 学习一个回归树，得到 $ T(x;\Theta_{m}) $<br>– (c)更新 $ f_{m}(x)=f_{m-1}(x)+T(x;\Theta_{m}) $</li>
<li>(3) 得到回归问题提升树 $ f_{M}(x)=\sum_{m=1}^{M}T(x;\Theta_{m}) $</li>
</ul>
<h1 id="梯度提升树-GBDT"><a href="#梯度提升树-GBDT" class="headerlink" title="梯度提升树(GBDT)"></a>梯度提升树(GBDT)</h1><h2 id="负梯度拟合"><a href="#负梯度拟合" class="headerlink" title="负梯度拟合"></a>负梯度拟合</h2><p>GBDT损失函数拟合方法采用的是 Freidman 提出的损失函数负梯度来拟合本轮损失近似值，进而拟合一个CART回归树。第t轮的第i个样本的损失函数的负梯度表示为：</p>
<center>$$ r_{ti}=-\left [ \frac{\partial L(y_{i},f(x_{i})))}{\partial f(x_{i})} \right ]_{f(x)=f_{t-1}(x)} $$</center><br>利用 $ (x_{i}, r_{ti})(i=1,2,…,m) $ ，可以拟合一颗CART回归树，其对应的叶子点区域 $ R_{tj}, j=1,2,…,J $ .其中J为叶子结点个数。<br><br>针对每一个叶子结点的样本，我们求出使损失函数最小，也就是拟合叶子结点最好的输出值 $ c_{tj} $ 如下：<br><center>$$ c_{tj}=\underbrace{argmin}_{c}\sum_{x_{i}\epsilon R_{tj}}L(y_{i},f_{t-1}(x_{i})+c) $$</center><br>这样就可以得到本轮决策树拟合函数如下：<br><center>$$ h_{t}(x)=\sum_{j=1}^{J}c_{tj}I(x\epsilon R_{tj}) $$</center><br>从而本轮最终得到的强学习器的表达式为：<br><center>$$ f_{t}(x)=f_{t-1}(x) + \sum_{j=1}^{J}c_{tj}I(x\epsilon R_{tj}) $$</center><br>通过损失函数的负梯度来拟合，我们找到了一种通用的拟合损失误差的办法，这样无轮是分类问题还是回归问题，我们通过其损失函数的负梯度的拟合，就可以用GBDT来解决我们的分类回归问题。区别仅仅在于损失函数不同导致的负梯度不同而已。<br><br>## GBDT回归问题<br><br>输入: 训练数据集 $ T=((x_{1}, y_{1}),(x_{2},y_{2}),…,(x_{N},y_{N})),x_{i}\epsilon \chi \subseteq \mathbb{R}^{n} $ ;损失函数 $ L(y,f(x)) $<br><br>输出：回归树 $ \hat{f}(x) $<br><br>- (1) 初始化: $ f_{0}(x)=arg\underset{c}{min}\sum_{i=1}^{N}L(y_{i},c) $<br>- (2) 对迭代次数 $ t=1,2,…,T $ 有：<br>– (a) 对 $ i=1,2,..,N $ ，计算：$  r_{ti}=-\left [ \frac{\partial L(y_{i},f(x_{i})))}{\partial f(x_{i})} \right ]_{f(x)=f_{t-1}(x)} $<br>– (b) 对 $ (x_{i},r_{ti}) $ 拟合一个回归树，得到第 t 课树的叶节点区域 $ R_{tj}, j=1,2,…,J $<br>– (c) 对 $ j=1,2,…,J $ , 计算 $ c_{tj}=\underbrace{argmin}_{c}\sum_{x_{i}\epsilon R_{tj}}L(y_{i},f_{t-1}(x_{i})+c) $<br>– (d) 更新 $ f_{t}(x)=f_{t-1}(x) + \sum_{j=1}^{J}c_{tj}I(x\epsilon R_{tj}) $<br>- (3) 得到强学习器为:<br><center>$$ f(x)=f_{T}(x)=f_{0}(x)+\sum_{t=1}^{T}\sum_{j=1}^{J}c_{tj}I(x\epsilon R_{tj}) $$</center>

<h2 id="二类分类问题"><a href="#二类分类问题" class="headerlink" title="二类分类问题"></a>二类分类问题</h2><p>对于二元GBDT，使用类似于逻辑回归的对数似然损失函数，则损失函数为：</p>
<center>$$ L(y,f(X))=log(1+exp(-yf(x))) $$</center>

<p>其中 $ y\epsilon(-1,+1) $ .则此时的负梯度误差为:</p>
<center>$$ r_{ti}=-\left [ \frac{\partial L(y_{i},f(x_{i})))}{\partial f(x_{i})} \right ]_{f(x)=f_{t-1}(x)}=y_{i}/(1+exp(y_{i}f(x_{i}))) $$</center>

<p>对于生成的决策树，各个叶子节点的最佳负梯度拟合值为:</p>
<center>$$ c_{tj}=arg\underset{c}{min}\sum_{x_{i}\epsilon R_{tj}}log(1+exp(-y_{i}(f_{t-1}(x_{i})+c))) $$</center>

<p>由于上式比较难以优化，一般使用近似值代替为:</p>
<center>$$ c_{tj}=\sum_{x_{i}\epsilon R_{tj}}r_{ti}/\sum_{x_{i}\epsilon R_{tj}}|r_{ti}|(1-|r_{ti}|) $$</center>

<p>除了负梯度计算和叶子节点的最佳负梯度拟合的线性搜索，二元GBDT分类和GBDT回归算法过程相同。</p>
<h2 id="多元分类问题"><a href="#多元分类问题" class="headerlink" title="多元分类问题"></a>多元分类问题</h2><p>多元 GBDT 要比二元 GBDT 复杂一些，对应的多元逻辑回归和二元逻辑回归的复杂度差别。假设类别树设为K,则此时的对数似然损失函数为：</p>
<center>$$ L(y,f(x))=-\sum_{k=1}^{K}y_{k}logp_{k}(x) $$</center>

<p>其中，如果样本输出类别为k, 则 $ y_{k}=1 $, 第k类的概率 $ P_{k}(x) $ 的表达式为：</p>
<center>$$ p_{k}=exp(f_{k}(x))/\sum_{l=1}^{K}exp(f_{l}(x)) $$</center>

<p>通过上面两式，可以推导出，第 t 轮的第i个样本对应类别l的负梯度误差为:</p>
<center>$$ r_{til}=-\left [ \frac{\partial L(y_{i},f(x_{i}))}{\partial f(x_{i})} \right ]_{f_{k}(x)=f_{l,t-1}(x)}=y_{il}-p_{l,t-1}(x_{i}) $$</center>

<p>观察上式可以得出，这里的误差是样本i对应类别l的真实概率和t-1轮预测概率的差值。</p>
<p>对于生成的决策树，我们各个叶子节点的最佳负梯度拟合值为：</p>
<center>$$ c_{tjl}=arg\underset{c_{jl}}{min}\sum_{i=0}^{m}\sum_{k=1}^{K}L(y_{k},f_{t-1,l}(x)+\sum_{j=0}^{J}c_{jl}I(x_{i}\epsilon R_{tjl})) $$</center>

<p>由于上式比较难以优化，一般采用的近似替代值为：</p>
<center>$$ c_{tjl}=\frac{K-1}{K}\frac{\sum_{x_{i}\epsilon R_{tjl}}r_{til}}{\sum_{x_{i}\epsilon R_{tjl}}|r_{til}|(1-|r_{til}|)} $$</center>

<h3 id="GBDT-常用损失函数"><a href="#GBDT-常用损失函数" class="headerlink" title="GBDT 常用损失函数"></a>GBDT 常用损失函数</h3><h3 id="GBDT-的正则化"><a href="#GBDT-的正则化" class="headerlink" title="GBDT 的正则化"></a>GBDT 的正则化</h3>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/03/AdaBoost/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenxiaolong">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xiaolongc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/03/AdaBoost/" itemprop="url">2. AdaBoost</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-03T10:10:23+08:00">
                2019-08-03
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">machine learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="提升方法的基本思路"><a href="#提升方法的基本思路" class="headerlink" title="提升方法的基本思路"></a>提升方法的基本思路</h1><p>理论基础：</p>
<p>强可学习(strongly learning)：在概率近似正确(probably approximately correct, PAC)学习框架下，一个概念(一个类)如果存在一个多项式的学习算法能够学习它，并且正确率很高，那么称他为强可学习的。</p>
<p>弱可学习(weakly learnable): 一个概念，如果存在一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测好，那么称这个概念为弱可学习的。</p>
<p>Schapire证明强可学习与弱可学习是等价的。即在PAC学习框架下，一个概念是强可学习的充分必要条件是这个概念是弱可学习的。这样如果发现了“弱学习算法”能否将他提升为“强可学习算法”。<font color="orange">大多数的提升方法都是改变训练数据的概率分布(训练数据的权值分布)，针对不同的训练数据分布调用弱学习算法学习一系列弱分类器。</font>下面介绍最典型的AdaBoost算法。</p>
<p>还有两个问题是：</p>
<p>1) 每一轮如何改变训练数据的权值或概率分布？</p>
<p>AdaBoost的做法是提高被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值。</p>
<p>2) 如何将弱分类器组合为一个强分类器？</p>
<p>AdaBoost 采取加权多数表决方法，加大分类误差率小的弱分类器的权重，使其在表决中起较大作用，减小分类误差率大的弱分类器的权值，使其表决中起较小的作用。</p>
<h1 id="AdaBoost算法"><a href="#AdaBoost算法" class="headerlink" title="AdaBoost算法"></a>AdaBoost算法</h1><h2 id="AdaBoost二分类算法"><a href="#AdaBoost二分类算法" class="headerlink" title="AdaBoost二分类算法"></a>AdaBoost二分类算法</h2><p>假设给定一个二分类训练数据集：</p>
<center>$$ T=((x_{1},y_{1}),(x_{2},y_{2}),…,(x_{N},y_{N})) $$</center>

<p>其中，每个样本点由实例与标记组成，实例 $ x_{i}\epsilon\chi\subseteq\mathbb{R}_{n} $ , 标记 $ y_{i}\epsilon Y =(-1,+1) $ , X 是实例空间，Y是标记集合。</p>
<p>算法：AdaBoost </p>
<p>输入：训练数据集 $ T=((x_{1}, y_{1}),(x_{2},y_{2}),…,(x_{N},y_{N})) $ ,其中 $ x_{i}\epsilon\chi \subseteq\mathbb{R}_{n},y_{i}\epsilon Y =(-1,+1) $ ;弱学习算法。</p>
<p>输出：最终分类器G(x).</p>
<ul>
<li>(1) 初始化训练数据的权值分布：<center>$$ D_{1}=(w_{11},…,w_{1i},…,w_{1N}), w_{1i}=\frac{1}{N}, i=1,2,…,N $$</center></li>
<li>(2) 对 m=1,2,…,M<br>– (a) 使用具有权值分布 $ D_{m} $ 的训练数据集学习，得到基本分类器：<br><center>$$ G_{m}(x):\chi \rightarrow (-1,+1). $$</center><br>– (b) 计算 $ G_{m}(x) $ 在训练数据集上的分类误差率：<br><center>$$ e_{m}=P(G_{m}(x_{i})\neq y_{i})=\sum_{i=1}^{N}w_{mi}I(G_{m}(x_{i})\neq y_{i}) $$</center><br>– (c) 计算 $ G_{m}(x) $ 的系数：<br><center>$$ \alpha_{m}=\frac{1}{2}log\frac{1-e_{m}}{e_{m}} $$</center><br>– (d) 更新训练数据集的权值分布：<br><center>$$ D_{m+1}=(w_{m+1,1},…,w_{m+1,i},…,w_{m+1,N}) $$</center><br><center>$$ w_{m+1,i}=\frac{w_{mi}}{Z_{m}}exp(-\alpha_{m}y_{i}G_{m}(x_{i})),i=1,2,…,N $$</center><br>这里， $ Z_{m} $ 是规范因子<br><center>$$ Z_{m}=\sum_{i=1}^{N}w_{mi}exp(-\alpha_{m}y_{i}G_{m}(x_{i})) $$</center><br>它使 $ D_{m+1} $ 成为一个概率分布.</li>
<li>(3) 构建基本分类器的线性组合<center>$$ f(x)=\sum_{m=1}^{M}\alpha_{m}G_{m}(x) $$</center><br>得到最终分类器：<br><center>$$ G(x)=sign(f(x))=sign(\sum_{m=1}^{M}\alpha_{m}G_{m}(x)) $$</center>

</li>
</ul>
<h2 id="AdaBoost回归问题算法流程"><a href="#AdaBoost回归问题算法流程" class="headerlink" title="AdaBoost回归问题算法流程"></a>AdaBoost回归问题算法流程</h2><p>来源于：<a href="https://www.cnblogs.com/pinard/p/6133937.html" target="_blank" rel="noopener">集成学习之Adaboost算法原理小结</a></p>
<p>输入：样本集 $ T=((x_{1},y_{1}),(x_{2},y_{2}),…,(x_{m},y_{m})) $ , 弱学习器算法，弱学习器迭代器K.</p>
<p>输出：强学习器 $ f(x) $</p>
<ul>
<li>(1) 初始化样本权重：<center>$$ D_{1}=(w_{11},…,w_{1i},…,w_{1N}), w_{1i}=\frac{1}{N}, i=1,2,…,N $$</center></li>
<li>(2) 对于k=1,2,…,k:<br>– a) 使用具有权重 $ D_{k} $ 的样本集来训练数据，得到弱学习器 $ G_{k}(x) $<br>– b) 计算训练集上的最大误差： $ E_{k}=max|y_{i} - G_{k}(x_{i})|, i=1,2,…,m $<br>– c) 计算每个样本相对误差：<br>— 如果是线性误差，则 $ e_{ki} = \frac{|y_{i}-G_{k}(x_{i})|}{E_{k}} $<br>— 如果是平方误差，则 $ e_{ki} = \frac{(y_{i}-G_{k}(x_{i}))^{2}}{E_{k}^{2}} $<br>— 如果是指数误差，则 $ e_{ki} =  1-exp(\frac{-|y_{i}-G_{k}(x_{i})|}{E_{k}}) $<br>– d) 计算回归误差率： $ e_{k}=\sum_{i=1}^{m}w_{ki}e_{ki} $<br>– e) 计算弱学习器系数： $ \alpha_{k} = \frac{e_{k}}{1-e_{k}} $<br>– f) 更新样本集的权重分布： $ w_{k+1,i}=\frac{w_{ki}}{Z_{k}}\alpha_{k}^{1-e_{ki}} $ ,其中 $ Z_{k} $ 是规范化因子： $ Z_{k}=\sum_{i=1}^{m}w_{ki}\alpha_{k}^{1-e_{ki}} $ .</li>
<li>(3) 构建最终强学习器为： $ f(x)=G_{k*}(x) $ .</li>
</ul>
<p>其中， $ G_ {k∗}(x) $ 是所有 $ ln\frac{1}{\alpha_{k}}, k=1,2,…,K $的中位数值对应序号k∗对应的弱学习器。</p>
<h1 id="AdaBoost的解释：前向分布算法"><a href="#AdaBoost的解释：前向分布算法" class="headerlink" title="AdaBoost的解释：前向分布算法"></a>AdaBoost的解释：前向分布算法</h1>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="chenxiaolong">
            
              <p class="site-author-name" itemprop="name">chenxiaolong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/xiaolongc929" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:xiaolongc929@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://plus.google.com/xiaolongc929" target="_blank" title="Google">
                      
                        <i class="fa fa-fw fa-google"></i>Google</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">chenxiaolong</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
